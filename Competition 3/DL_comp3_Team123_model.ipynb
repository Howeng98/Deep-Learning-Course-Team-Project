{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 3: Reverse Image Caption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n",
      "'chmod' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datalab-cup3-reverse-image-caption-2021.zip to d:\\NTHU\\DL_course\\cup3\\Deep-Learning-Course-Team-Project\\Competition 3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/667M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/667M [00:00<02:08, 5.43MB/s]\n",
      "  0%|          | 2.00M/667M [00:00<01:53, 6.15MB/s]\n",
      "  0%|          | 3.00M/667M [00:00<01:52, 6.19MB/s]\n",
      "  1%|          | 4.00M/667M [00:00<01:43, 6.68MB/s]\n",
      "  1%|          | 5.00M/667M [00:00<01:48, 6.40MB/s]\n",
      "  1%|          | 6.00M/667M [00:00<01:39, 7.00MB/s]\n",
      "  1%|          | 7.00M/667M [00:01<01:50, 6.28MB/s]\n",
      "  1%|          | 8.00M/667M [00:01<01:48, 6.34MB/s]\n",
      "  1%|▏         | 9.00M/667M [00:01<01:44, 6.60MB/s]\n",
      "  2%|▏         | 10.0M/667M [00:01<01:43, 6.64MB/s]\n",
      "  2%|▏         | 11.0M/667M [00:01<01:35, 7.21MB/s]\n",
      "  2%|▏         | 12.0M/667M [00:01<01:29, 7.67MB/s]\n",
      "  2%|▏         | 13.0M/667M [00:02<01:43, 6.61MB/s]\n",
      "  2%|▏         | 14.0M/667M [00:02<01:47, 6.35MB/s]\n",
      "  2%|▏         | 15.0M/667M [00:02<01:48, 6.27MB/s]\n",
      "  2%|▏         | 16.0M/667M [00:02<01:42, 6.65MB/s]\n",
      "  3%|▎         | 17.0M/667M [00:02<01:37, 7.02MB/s]\n",
      "  3%|▎         | 18.0M/667M [00:02<01:40, 6.77MB/s]\n",
      "  3%|▎         | 19.0M/667M [00:02<01:32, 7.31MB/s]\n",
      "  3%|▎         | 20.0M/667M [00:03<01:43, 6.57MB/s]\n",
      "  3%|▎         | 21.0M/667M [00:03<01:54, 5.93MB/s]\n",
      "  3%|▎         | 22.0M/667M [00:03<01:46, 6.35MB/s]\n",
      "  3%|▎         | 23.0M/667M [00:03<01:36, 6.97MB/s]\n",
      "  4%|▎         | 24.0M/667M [00:03<01:35, 7.03MB/s]\n",
      "  4%|▍         | 25.0M/667M [00:03<01:33, 7.21MB/s]\n",
      "  4%|▍         | 26.0M/667M [00:04<01:26, 7.78MB/s]\n",
      "  4%|▍         | 27.0M/667M [00:04<01:26, 7.79MB/s]\n",
      "  4%|▍         | 28.0M/667M [00:04<01:24, 7.89MB/s]\n",
      "  4%|▍         | 29.0M/667M [00:04<01:24, 7.91MB/s]\n",
      "  5%|▍         | 30.0M/667M [00:04<01:31, 7.31MB/s]\n",
      "  5%|▍         | 32.0M/667M [00:04<01:17, 8.58MB/s]\n",
      "  5%|▍         | 33.0M/667M [00:04<01:14, 8.92MB/s]\n",
      "  5%|▌         | 34.0M/667M [00:04<01:12, 9.12MB/s]\n",
      "  5%|▌         | 35.0M/667M [00:05<01:31, 7.24MB/s]\n",
      "  5%|▌         | 36.0M/667M [00:05<01:24, 7.85MB/s]\n",
      "  6%|▌         | 37.0M/667M [00:05<01:30, 7.33MB/s]\n",
      "  6%|▌         | 38.0M/667M [00:05<01:27, 7.51MB/s]\n",
      "  6%|▌         | 39.0M/667M [00:05<01:22, 8.00MB/s]\n",
      "  6%|▌         | 40.0M/667M [00:05<01:17, 8.44MB/s]\n",
      "  6%|▌         | 41.0M/667M [00:05<01:13, 8.90MB/s]\n",
      "  6%|▋         | 42.0M/667M [00:06<02:07, 5.15MB/s]\n",
      "  6%|▋         | 43.0M/667M [00:06<01:48, 6.01MB/s]\n",
      "  7%|▋         | 44.0M/667M [00:06<02:39, 4.08MB/s]\n",
      "  7%|▋         | 45.0M/667M [00:07<02:11, 4.97MB/s]\n",
      "  7%|▋         | 46.0M/667M [00:07<01:55, 5.62MB/s]\n",
      "  7%|▋         | 47.0M/667M [00:07<01:41, 6.41MB/s]\n",
      "  7%|▋         | 48.0M/667M [00:07<01:40, 6.43MB/s]\n",
      "  7%|▋         | 49.0M/667M [00:07<01:30, 7.17MB/s]\n",
      "  8%|▊         | 50.0M/667M [00:07<01:23, 7.76MB/s]\n",
      "  8%|▊         | 52.0M/667M [00:07<01:18, 8.17MB/s]\n",
      "  8%|▊         | 54.0M/667M [00:08<01:12, 8.90MB/s]\n",
      "  8%|▊         | 56.0M/667M [00:08<01:07, 9.42MB/s]\n",
      "  9%|▊         | 57.0M/667M [00:08<01:08, 9.38MB/s]\n",
      "  9%|▊         | 58.0M/667M [00:08<01:06, 9.54MB/s]\n",
      "  9%|▉         | 59.0M/667M [00:08<01:05, 9.67MB/s]\n",
      "  9%|▉         | 60.0M/667M [00:08<01:12, 8.72MB/s]\n",
      "  9%|▉         | 61.0M/667M [00:08<01:11, 8.94MB/s]\n",
      "  9%|▉         | 63.0M/667M [00:09<01:08, 9.18MB/s]\n",
      " 10%|▉         | 65.0M/667M [00:09<01:06, 9.55MB/s]\n",
      " 10%|▉         | 66.0M/667M [00:09<01:05, 9.63MB/s]\n",
      " 10%|█         | 68.0M/667M [00:09<01:01, 10.2MB/s]\n",
      " 10%|█         | 69.0M/667M [00:09<01:06, 9.40MB/s]\n",
      " 11%|█         | 70.0M/667M [00:09<01:09, 8.94MB/s]\n",
      " 11%|█         | 71.0M/667M [00:10<01:14, 8.36MB/s]\n",
      " 11%|█         | 72.0M/667M [00:10<01:17, 8.01MB/s]\n",
      " 11%|█         | 73.0M/667M [00:10<01:20, 7.71MB/s]\n",
      " 11%|█         | 74.0M/667M [00:10<01:16, 8.08MB/s]\n",
      " 11%|█▏        | 75.0M/667M [00:10<01:14, 8.36MB/s]\n",
      " 12%|█▏        | 77.0M/667M [00:10<01:07, 9.19MB/s]\n",
      " 12%|█▏        | 79.0M/667M [00:10<01:03, 9.72MB/s]\n",
      " 12%|█▏        | 81.0M/667M [00:11<01:01, 9.96MB/s]\n",
      " 12%|█▏        | 82.0M/667M [00:11<01:01, 10.0MB/s]\n",
      " 12%|█▏        | 83.0M/667M [00:11<01:02, 9.73MB/s]\n",
      " 13%|█▎        | 84.0M/667M [00:11<01:02, 9.71MB/s]\n",
      " 13%|█▎        | 86.0M/667M [00:11<01:00, 10.1MB/s]\n",
      " 13%|█▎        | 88.0M/667M [00:11<00:59, 10.2MB/s]\n",
      " 13%|█▎        | 89.0M/667M [00:11<00:59, 10.2MB/s]\n",
      " 14%|█▎        | 90.0M/667M [00:12<01:01, 9.84MB/s]\n",
      " 14%|█▎        | 91.0M/667M [00:12<01:16, 7.87MB/s]\n",
      " 14%|█▍        | 92.0M/667M [00:12<01:13, 8.16MB/s]\n",
      " 14%|█▍        | 93.0M/667M [00:12<01:22, 7.30MB/s]\n",
      " 14%|█▍        | 95.0M/667M [00:12<01:10, 8.48MB/s]\n",
      " 15%|█▍        | 97.0M/667M [00:12<01:04, 9.19MB/s]\n",
      " 15%|█▍        | 98.0M/667M [00:13<01:03, 9.39MB/s]\n",
      " 15%|█▍        | 99.0M/667M [00:13<01:04, 9.20MB/s]\n",
      " 15%|█▌        | 100M/667M [00:13<01:38, 6.06MB/s] \n",
      " 15%|█▌        | 101M/667M [00:13<01:31, 6.49MB/s]\n",
      " 15%|█▌        | 102M/667M [00:13<01:22, 7.15MB/s]\n",
      " 15%|█▌        | 103M/667M [00:13<01:19, 7.48MB/s]\n",
      " 16%|█▌        | 104M/667M [00:14<01:12, 8.13MB/s]\n",
      " 16%|█▌        | 105M/667M [00:14<01:11, 8.21MB/s]\n",
      " 16%|█▌        | 106M/667M [00:14<01:07, 8.73MB/s]\n",
      " 16%|█▌        | 108M/667M [00:14<01:10, 8.32MB/s]\n",
      " 16%|█▋        | 109M/667M [00:14<01:07, 8.65MB/s]\n",
      " 17%|█▋        | 110M/667M [00:14<01:05, 8.96MB/s]\n",
      " 17%|█▋        | 111M/667M [00:14<01:03, 9.24MB/s]\n",
      " 17%|█▋        | 113M/667M [00:15<00:59, 9.75MB/s]\n",
      " 17%|█▋        | 114M/667M [00:15<00:59, 9.68MB/s]\n",
      " 17%|█▋        | 116M/667M [00:15<00:59, 9.69MB/s]\n",
      " 18%|█▊        | 117M/667M [00:15<00:59, 9.76MB/s]\n",
      " 18%|█▊        | 118M/667M [00:15<00:58, 9.75MB/s]\n",
      " 18%|█▊        | 119M/667M [00:15<00:58, 9.82MB/s]\n",
      " 18%|█▊        | 120M/667M [00:15<01:00, 9.49MB/s]\n",
      " 18%|█▊        | 121M/667M [00:15<00:59, 9.55MB/s]\n",
      " 18%|█▊        | 122M/667M [00:15<00:59, 9.66MB/s]\n",
      " 18%|█▊        | 123M/667M [00:16<00:59, 9.59MB/s]\n",
      " 19%|█▊        | 124M/667M [00:16<00:58, 9.76MB/s]\n",
      " 19%|█▉        | 125M/667M [00:16<00:59, 9.51MB/s]\n",
      " 19%|█▉        | 126M/667M [00:16<01:00, 9.32MB/s]\n",
      " 19%|█▉        | 127M/667M [00:16<01:07, 8.35MB/s]\n",
      " 19%|█▉        | 128M/667M [00:16<01:21, 6.96MB/s]\n",
      " 19%|█▉        | 129M/667M [00:16<01:14, 7.53MB/s]\n",
      " 20%|█▉        | 131M/667M [00:17<01:12, 7.76MB/s]\n",
      " 20%|█▉        | 132M/667M [00:17<01:10, 7.99MB/s]\n",
      " 20%|█▉        | 133M/667M [00:17<01:08, 8.21MB/s]\n",
      " 20%|██        | 134M/667M [00:17<01:06, 8.35MB/s]\n",
      " 20%|██        | 136M/667M [00:17<00:59, 9.27MB/s]\n",
      " 21%|██        | 137M/667M [00:17<00:58, 9.43MB/s]\n",
      " 21%|██        | 138M/667M [00:17<00:58, 9.44MB/s]\n",
      " 21%|██        | 139M/667M [00:18<00:57, 9.59MB/s]\n",
      " 21%|██        | 140M/667M [00:18<00:57, 9.65MB/s]\n",
      " 21%|██        | 141M/667M [00:18<00:56, 9.83MB/s]\n",
      " 21%|██▏       | 142M/667M [00:18<00:58, 9.37MB/s]\n",
      " 21%|██▏       | 143M/667M [00:18<00:59, 9.23MB/s]\n",
      " 22%|██▏       | 144M/667M [00:18<01:00, 9.12MB/s]\n",
      " 22%|██▏       | 145M/667M [00:18<00:58, 9.39MB/s]\n",
      " 22%|██▏       | 146M/667M [00:18<01:09, 7.90MB/s]\n",
      " 22%|██▏       | 147M/667M [00:19<02:50, 3.19MB/s]\n",
      " 22%|██▏       | 148M/667M [00:19<02:14, 4.03MB/s]\n",
      " 22%|██▏       | 149M/667M [00:19<01:54, 4.73MB/s]\n",
      " 23%|██▎       | 150M/667M [00:20<01:37, 5.53MB/s]\n",
      " 23%|██▎       | 151M/667M [00:20<01:25, 6.34MB/s]\n",
      " 23%|██▎       | 152M/667M [00:20<01:18, 6.87MB/s]\n",
      " 23%|██▎       | 153M/667M [00:20<01:12, 7.39MB/s]\n",
      " 23%|██▎       | 154M/667M [00:20<01:08, 7.82MB/s]\n",
      " 23%|██▎       | 155M/667M [00:20<01:09, 7.73MB/s]\n",
      " 23%|██▎       | 156M/667M [00:20<01:05, 8.16MB/s]\n",
      " 24%|██▎       | 157M/667M [00:20<01:05, 8.19MB/s]\n",
      " 24%|██▎       | 158M/667M [00:21<01:15, 7.06MB/s]\n",
      " 24%|██▍       | 159M/667M [00:21<01:16, 6.96MB/s]\n",
      " 24%|██▍       | 160M/667M [00:21<01:13, 7.22MB/s]\n",
      " 24%|██▍       | 161M/667M [00:21<01:08, 7.72MB/s]\n",
      " 24%|██▍       | 162M/667M [00:21<01:03, 8.37MB/s]\n",
      " 24%|██▍       | 163M/667M [00:21<01:03, 8.26MB/s]\n",
      " 25%|██▍       | 164M/667M [00:21<01:00, 8.68MB/s]\n",
      " 25%|██▍       | 166M/667M [00:22<00:57, 9.10MB/s]\n",
      " 25%|██▌       | 167M/667M [00:22<00:56, 9.21MB/s]\n",
      " 25%|██▌       | 168M/667M [00:22<00:56, 9.19MB/s]\n",
      " 25%|██▌       | 169M/667M [00:22<00:56, 9.31MB/s]\n",
      " 26%|██▌       | 170M/667M [00:22<00:58, 8.91MB/s]\n",
      " 26%|██▌       | 171M/667M [00:22<00:57, 9.03MB/s]\n",
      " 26%|██▌       | 172M/667M [00:22<00:56, 9.15MB/s]\n",
      " 26%|██▌       | 173M/667M [00:22<00:57, 9.01MB/s]\n",
      " 26%|██▋       | 175M/667M [00:23<00:53, 9.68MB/s]\n",
      " 26%|██▋       | 176M/667M [00:23<00:53, 9.61MB/s]\n",
      " 27%|██▋       | 177M/667M [00:23<00:56, 9.06MB/s]\n",
      " 27%|██▋       | 178M/667M [00:23<00:54, 9.39MB/s]\n",
      " 27%|██▋       | 179M/667M [00:23<00:55, 9.20MB/s]\n",
      " 27%|██▋       | 180M/667M [00:23<00:53, 9.49MB/s]\n",
      " 27%|██▋       | 181M/667M [00:23<00:54, 9.37MB/s]\n",
      " 27%|██▋       | 182M/667M [00:23<00:54, 9.27MB/s]\n",
      " 27%|██▋       | 183M/667M [00:23<00:55, 9.21MB/s]\n",
      " 28%|██▊       | 184M/667M [00:24<00:53, 9.49MB/s]\n",
      " 28%|██▊       | 185M/667M [00:24<00:55, 9.04MB/s]\n",
      " 28%|██▊       | 186M/667M [00:24<00:54, 9.31MB/s]\n",
      " 28%|██▊       | 187M/667M [00:24<00:54, 9.27MB/s]\n",
      " 28%|██▊       | 188M/667M [00:24<00:56, 8.82MB/s]\n",
      " 28%|██▊       | 189M/667M [00:24<01:17, 6.50MB/s]\n",
      " 29%|██▊       | 190M/667M [00:24<01:10, 7.06MB/s]\n",
      " 29%|██▊       | 191M/667M [00:25<01:04, 7.68MB/s]\n",
      " 29%|██▉       | 192M/667M [00:25<01:01, 8.07MB/s]\n",
      " 29%|██▉       | 193M/667M [00:25<00:59, 8.31MB/s]\n",
      " 29%|██▉       | 194M/667M [00:25<00:59, 8.28MB/s]\n",
      " 29%|██▉       | 195M/667M [00:25<01:08, 7.25MB/s]\n",
      " 29%|██▉       | 196M/667M [00:26<03:02, 2.71MB/s]\n",
      " 30%|██▉       | 197M/667M [00:26<02:23, 3.44MB/s]\n",
      " 30%|██▉       | 198M/667M [00:26<01:54, 4.30MB/s]\n",
      " 30%|██▉       | 199M/667M [00:26<01:34, 5.18MB/s]\n",
      " 30%|███       | 200M/667M [00:26<01:21, 5.99MB/s]\n",
      " 30%|███       | 201M/667M [00:27<01:12, 6.77MB/s]\n",
      " 30%|███       | 202M/667M [00:27<01:05, 7.42MB/s]\n",
      " 30%|███       | 203M/667M [00:27<01:18, 6.20MB/s]\n",
      " 31%|███       | 204M/667M [00:27<01:10, 6.85MB/s]\n",
      " 31%|███       | 205M/667M [00:27<01:05, 7.41MB/s]\n",
      " 31%|███       | 206M/667M [00:27<00:59, 8.06MB/s]\n",
      " 31%|███       | 207M/667M [00:27<00:57, 8.43MB/s]\n",
      " 31%|███▏      | 209M/667M [00:28<00:50, 9.49MB/s]\n",
      " 32%|███▏      | 211M/667M [00:28<01:14, 6.37MB/s]\n",
      " 32%|███▏      | 212M/667M [00:28<01:08, 6.97MB/s]\n",
      " 32%|███▏      | 214M/667M [00:28<00:59, 7.93MB/s]\n",
      " 32%|███▏      | 215M/667M [00:28<00:57, 8.18MB/s]\n",
      " 32%|███▏      | 216M/667M [00:29<01:01, 7.64MB/s]\n",
      " 33%|███▎      | 217M/667M [00:29<02:13, 3.53MB/s]\n",
      " 33%|███▎      | 219M/667M [00:31<03:41, 2.12MB/s]\n",
      " 33%|███▎      | 220M/667M [00:31<03:01, 2.58MB/s]\n",
      " 33%|███▎      | 221M/667M [00:31<02:27, 3.16MB/s]\n",
      " 33%|███▎      | 222M/667M [00:31<02:01, 3.85MB/s]\n",
      " 33%|███▎      | 223M/667M [00:31<01:44, 4.43MB/s]\n",
      " 34%|███▎      | 224M/667M [00:32<01:29, 5.21MB/s]\n",
      " 34%|███▍      | 225M/667M [00:32<01:16, 6.08MB/s]\n",
      " 34%|███▍      | 226M/667M [00:32<02:40, 2.88MB/s]\n",
      " 34%|███▍      | 227M/667M [00:33<02:27, 3.12MB/s]\n",
      " 34%|███▍      | 229M/667M [00:33<01:41, 4.53MB/s]\n",
      " 35%|███▍      | 230M/667M [00:33<01:27, 5.24MB/s]\n",
      " 35%|███▍      | 231M/667M [00:33<01:15, 6.02MB/s]\n",
      " 35%|███▍      | 232M/667M [00:33<01:08, 6.69MB/s]\n",
      " 35%|███▍      | 233M/667M [00:33<01:02, 7.26MB/s]\n",
      " 35%|███▌      | 234M/667M [00:33<00:58, 7.78MB/s]\n",
      " 35%|███▌      | 236M/667M [00:34<00:50, 8.86MB/s]\n",
      " 36%|███▌      | 237M/667M [00:34<00:50, 8.85MB/s]\n",
      " 36%|███▌      | 238M/667M [00:34<00:50, 8.92MB/s]\n",
      " 36%|███▌      | 239M/667M [00:34<00:50, 8.86MB/s]\n",
      " 36%|███▌      | 241M/667M [00:34<00:48, 9.19MB/s]\n",
      " 36%|███▋      | 243M/667M [00:35<01:28, 5.01MB/s]\n",
      " 37%|███▋      | 244M/667M [00:35<01:26, 5.12MB/s]\n",
      " 37%|███▋      | 245M/667M [00:35<01:29, 4.93MB/s]\n",
      " 37%|███▋      | 246M/667M [00:36<01:19, 5.52MB/s]\n",
      " 37%|███▋      | 247M/667M [00:36<01:19, 5.56MB/s]\n",
      " 37%|███▋      | 248M/667M [00:36<01:38, 4.46MB/s]\n",
      " 37%|███▋      | 249M/667M [00:36<01:33, 4.71MB/s]\n",
      " 38%|███▊      | 250M/667M [00:36<01:21, 5.36MB/s]\n",
      " 38%|███▊      | 251M/667M [00:37<01:18, 5.54MB/s]\n",
      " 38%|███▊      | 252M/667M [00:37<01:10, 6.17MB/s]\n",
      " 38%|███▊      | 254M/667M [00:37<00:59, 7.32MB/s]\n",
      " 38%|███▊      | 255M/667M [00:37<00:57, 7.51MB/s]\n",
      " 39%|███▊      | 257M/667M [00:37<00:59, 7.18MB/s]\n",
      " 39%|███▊      | 258M/667M [00:38<01:12, 5.88MB/s]\n",
      " 39%|███▉      | 260M/667M [00:38<01:23, 5.13MB/s]\n",
      " 39%|███▉      | 261M/667M [00:38<01:14, 5.67MB/s]\n",
      " 39%|███▉      | 262M/667M [00:38<01:07, 6.29MB/s]\n",
      " 39%|███▉      | 263M/667M [00:38<01:01, 6.94MB/s]\n",
      " 40%|███▉      | 264M/667M [00:39<00:55, 7.55MB/s]\n",
      " 40%|███▉      | 265M/667M [00:39<00:52, 8.05MB/s]\n",
      " 40%|███▉      | 266M/667M [00:39<00:54, 7.66MB/s]\n",
      " 40%|████      | 267M/667M [00:39<00:59, 7.09MB/s]\n",
      " 40%|████      | 268M/667M [00:39<01:03, 6.58MB/s]\n",
      " 40%|████      | 269M/667M [00:39<01:02, 6.69MB/s]\n",
      " 41%|████      | 270M/667M [00:39<00:57, 7.28MB/s]\n",
      " 41%|████      | 271M/667M [00:40<00:54, 7.65MB/s]\n",
      " 41%|████      | 272M/667M [00:40<00:53, 7.74MB/s]\n",
      " 41%|████      | 273M/667M [00:40<00:52, 7.87MB/s]\n",
      " 41%|████      | 274M/667M [00:40<00:52, 7.86MB/s]\n",
      " 41%|████▏     | 275M/667M [00:41<01:42, 4.02MB/s]\n",
      " 41%|████▏     | 276M/667M [00:41<01:27, 4.69MB/s]\n",
      " 42%|████▏     | 277M/667M [00:41<01:14, 5.50MB/s]\n",
      " 42%|████▏     | 278M/667M [00:41<01:06, 6.10MB/s]\n",
      " 42%|████▏     | 279M/667M [00:41<01:03, 6.44MB/s]\n",
      " 42%|████▏     | 280M/667M [00:41<00:57, 7.10MB/s]\n",
      " 42%|████▏     | 281M/667M [00:41<00:52, 7.72MB/s]\n",
      " 42%|████▏     | 282M/667M [00:41<00:52, 7.62MB/s]\n",
      " 42%|████▏     | 283M/667M [00:42<00:52, 7.71MB/s]\n",
      " 43%|████▎     | 284M/667M [00:42<00:51, 7.72MB/s]\n",
      " 43%|████▎     | 285M/667M [00:42<00:48, 8.24MB/s]\n",
      " 43%|████▎     | 286M/667M [00:42<00:45, 8.68MB/s]\n",
      " 43%|████▎     | 288M/667M [00:42<00:43, 9.23MB/s]\n",
      " 43%|████▎     | 289M/667M [00:42<00:42, 9.33MB/s]\n",
      " 44%|████▎     | 291M/667M [00:42<00:43, 8.98MB/s]\n",
      " 44%|████▍     | 293M/667M [00:43<00:40, 9.62MB/s]\n",
      " 44%|████▍     | 294M/667M [00:43<00:40, 9.70MB/s]\n",
      " 44%|████▍     | 296M/667M [00:43<00:38, 10.1MB/s]\n",
      " 45%|████▍     | 297M/667M [00:43<00:38, 10.2MB/s]\n",
      " 45%|████▍     | 298M/667M [00:43<00:41, 9.37MB/s]\n",
      " 45%|████▌     | 300M/667M [00:43<00:39, 9.81MB/s]\n",
      " 45%|████▌     | 301M/667M [00:43<00:38, 9.92MB/s]\n",
      " 45%|████▌     | 302M/667M [00:44<00:39, 9.70MB/s]\n",
      " 45%|████▌     | 303M/667M [00:44<00:38, 9.80MB/s]\n",
      " 46%|████▌     | 304M/667M [00:44<00:39, 9.70MB/s]\n",
      " 46%|████▌     | 306M/667M [00:44<00:38, 9.75MB/s]\n",
      " 46%|████▌     | 307M/667M [00:44<00:40, 9.26MB/s]\n",
      " 46%|████▌     | 308M/667M [00:44<00:39, 9.44MB/s]\n",
      " 46%|████▋     | 309M/667M [00:44<00:39, 9.61MB/s]\n",
      " 47%|████▋     | 311M/667M [00:45<00:36, 10.1MB/s]\n",
      " 47%|████▋     | 312M/667M [00:45<00:37, 10.0MB/s]\n",
      " 47%|████▋     | 313M/667M [00:45<00:37, 9.89MB/s]\n",
      " 47%|████▋     | 315M/667M [00:45<00:36, 10.1MB/s]\n",
      " 47%|████▋     | 316M/667M [00:45<00:36, 10.2MB/s]\n",
      " 48%|████▊     | 318M/667M [00:45<00:35, 10.4MB/s]\n",
      " 48%|████▊     | 319M/667M [00:45<00:36, 10.1MB/s]\n",
      " 48%|████▊     | 320M/667M [00:46<00:44, 8.26MB/s]\n",
      " 48%|████▊     | 321M/667M [00:46<00:48, 7.50MB/s]\n",
      " 48%|████▊     | 322M/667M [00:46<00:45, 7.86MB/s]\n",
      " 48%|████▊     | 323M/667M [00:46<00:42, 8.40MB/s]\n",
      " 49%|████▊     | 324M/667M [00:46<00:43, 8.21MB/s]\n",
      " 49%|████▉     | 325M/667M [00:46<00:41, 8.54MB/s]\n",
      " 49%|████▉     | 326M/667M [00:46<00:40, 8.92MB/s]\n",
      " 49%|████▉     | 327M/667M [00:46<00:40, 8.77MB/s]\n",
      " 49%|████▉     | 328M/667M [00:47<00:39, 8.94MB/s]\n",
      " 49%|████▉     | 329M/667M [00:47<00:39, 9.03MB/s]\n",
      " 50%|████▉     | 330M/667M [00:47<00:39, 8.88MB/s]\n",
      " 50%|████▉     | 331M/667M [00:47<00:38, 9.05MB/s]\n",
      " 50%|████▉     | 332M/667M [00:47<00:37, 9.36MB/s]\n",
      " 50%|████▉     | 333M/667M [00:47<00:37, 9.30MB/s]\n",
      " 50%|█████     | 334M/667M [00:47<00:37, 9.24MB/s]\n",
      " 50%|█████     | 335M/667M [00:47<00:38, 8.95MB/s]\n",
      " 50%|█████     | 336M/667M [00:47<00:39, 8.78MB/s]\n",
      " 51%|█████     | 337M/667M [00:48<00:37, 9.17MB/s]\n",
      " 51%|█████     | 338M/667M [00:48<00:37, 9.16MB/s]\n",
      " 51%|█████     | 339M/667M [00:48<00:36, 9.48MB/s]\n",
      " 51%|█████     | 340M/667M [00:48<00:36, 9.35MB/s]\n",
      " 51%|█████     | 341M/667M [00:48<00:35, 9.49MB/s]\n",
      " 51%|█████▏    | 342M/667M [00:48<00:35, 9.51MB/s]\n",
      " 51%|█████▏    | 343M/667M [00:48<00:35, 9.45MB/s]\n",
      " 52%|█████▏    | 344M/667M [00:48<00:36, 9.18MB/s]\n",
      " 52%|█████▏    | 345M/667M [00:48<00:36, 9.22MB/s]\n",
      " 52%|█████▏    | 346M/667M [00:49<00:36, 9.20MB/s]\n",
      " 52%|█████▏    | 347M/667M [00:49<00:50, 6.63MB/s]\n",
      " 52%|█████▏    | 348M/667M [00:50<01:43, 3.21MB/s]\n",
      " 52%|█████▏    | 349M/667M [00:50<01:25, 3.88MB/s]\n",
      " 53%|█████▎    | 350M/667M [00:50<01:19, 4.17MB/s]\n",
      " 53%|█████▎    | 351M/667M [00:50<01:07, 4.89MB/s]\n",
      " 53%|█████▎    | 352M/667M [00:50<01:01, 5.38MB/s]\n",
      " 53%|█████▎    | 353M/667M [00:50<00:55, 5.92MB/s]\n",
      " 53%|█████▎    | 354M/667M [00:50<00:53, 6.08MB/s]\n",
      " 53%|█████▎    | 355M/667M [00:51<00:52, 6.25MB/s]\n",
      " 53%|█████▎    | 356M/667M [00:51<00:54, 5.97MB/s]\n",
      " 54%|█████▎    | 357M/667M [00:51<00:48, 6.63MB/s]\n",
      " 54%|█████▎    | 358M/667M [00:51<00:44, 7.31MB/s]\n",
      " 54%|█████▍    | 359M/667M [00:51<00:42, 7.53MB/s]\n",
      " 54%|█████▍    | 360M/667M [00:51<00:40, 7.95MB/s]\n",
      " 54%|█████▍    | 361M/667M [00:51<00:39, 8.07MB/s]\n",
      " 54%|█████▍    | 362M/667M [00:52<00:38, 8.31MB/s]\n",
      " 54%|█████▍    | 363M/667M [00:52<00:39, 8.00MB/s]\n",
      " 55%|█████▍    | 364M/667M [00:52<00:39, 8.02MB/s]\n",
      " 55%|█████▍    | 365M/667M [00:52<00:38, 8.23MB/s]\n",
      " 55%|█████▍    | 366M/667M [00:52<00:38, 8.27MB/s]\n",
      " 55%|█████▌    | 367M/667M [00:52<00:38, 8.10MB/s]\n",
      " 55%|█████▌    | 368M/667M [00:52<00:39, 7.99MB/s]\n",
      " 55%|█████▌    | 369M/667M [00:52<00:39, 7.94MB/s]\n",
      " 56%|█████▌    | 370M/667M [00:53<00:38, 8.03MB/s]\n",
      " 56%|█████▌    | 372M/667M [00:53<00:34, 9.01MB/s]\n",
      " 56%|█████▌    | 373M/667M [00:53<00:33, 9.30MB/s]\n",
      " 56%|█████▋    | 375M/667M [00:53<00:31, 9.62MB/s]\n",
      " 56%|█████▋    | 376M/667M [00:53<00:31, 9.59MB/s]\n",
      " 57%|█████▋    | 377M/667M [00:53<00:32, 9.37MB/s]\n",
      " 57%|█████▋    | 378M/667M [00:53<00:32, 9.40MB/s]\n",
      " 57%|█████▋    | 379M/667M [00:54<00:31, 9.53MB/s]\n",
      " 57%|█████▋    | 380M/667M [00:54<00:31, 9.66MB/s]\n",
      " 57%|█████▋    | 382M/667M [00:54<00:30, 9.86MB/s]\n",
      " 58%|█████▊    | 384M/667M [00:54<00:29, 10.1MB/s]\n",
      " 58%|█████▊    | 385M/667M [00:54<00:31, 9.32MB/s]\n",
      " 58%|█████▊    | 387M/667M [00:55<00:39, 7.49MB/s]\n",
      " 58%|█████▊    | 388M/667M [00:55<00:41, 6.98MB/s]\n",
      " 58%|█████▊    | 389M/667M [00:55<00:51, 5.63MB/s]\n",
      " 59%|█████▊    | 390M/667M [00:55<00:45, 6.32MB/s]\n",
      " 59%|█████▉    | 392M/667M [00:55<00:39, 7.36MB/s]\n",
      " 59%|█████▉    | 394M/667M [00:56<00:34, 8.22MB/s]\n",
      " 59%|█████▉    | 396M/667M [00:56<00:36, 7.76MB/s]\n",
      " 60%|█████▉    | 397M/667M [00:56<00:41, 6.76MB/s]\n",
      " 60%|█████▉    | 398M/667M [00:56<00:40, 6.89MB/s]\n",
      " 60%|█████▉    | 399M/667M [00:56<00:37, 7.41MB/s]\n",
      " 60%|██████    | 400M/667M [00:57<00:35, 7.89MB/s]\n",
      " 60%|██████    | 402M/667M [00:57<00:32, 8.55MB/s]\n",
      " 61%|██████    | 404M/667M [00:57<00:29, 9.19MB/s]\n",
      " 61%|██████    | 405M/667M [00:57<00:29, 9.28MB/s]\n",
      " 61%|██████    | 406M/667M [00:57<00:29, 9.42MB/s]\n",
      " 61%|██████    | 408M/667M [00:57<00:27, 9.93MB/s]\n",
      " 62%|██████▏   | 410M/667M [00:58<00:27, 9.74MB/s]\n",
      " 62%|██████▏   | 411M/667M [00:58<00:30, 8.66MB/s]\n",
      " 62%|██████▏   | 412M/667M [00:58<00:29, 8.92MB/s]\n",
      " 62%|██████▏   | 413M/667M [00:58<00:29, 9.09MB/s]\n",
      " 62%|██████▏   | 415M/667M [00:58<00:27, 9.70MB/s]\n",
      " 62%|██████▏   | 416M/667M [00:58<00:26, 9.81MB/s]\n",
      " 63%|██████▎   | 417M/667M [00:58<00:26, 9.79MB/s]\n",
      " 63%|██████▎   | 418M/667M [00:58<00:27, 9.63MB/s]\n",
      " 63%|██████▎   | 419M/667M [00:59<00:36, 7.20MB/s]\n",
      " 63%|██████▎   | 420M/667M [00:59<00:33, 7.78MB/s]\n",
      " 63%|██████▎   | 421M/667M [00:59<00:31, 8.18MB/s]\n",
      " 63%|██████▎   | 422M/667M [00:59<00:29, 8.70MB/s]\n",
      " 63%|██████▎   | 423M/667M [00:59<00:28, 8.95MB/s]\n",
      " 64%|██████▎   | 424M/667M [00:59<00:27, 9.16MB/s]\n",
      " 64%|██████▍   | 425M/667M [00:59<00:26, 9.43MB/s]\n",
      " 64%|██████▍   | 426M/667M [00:59<00:26, 9.61MB/s]\n",
      " 64%|██████▍   | 427M/667M [01:00<00:30, 8.33MB/s]\n",
      " 64%|██████▍   | 429M/667M [01:00<00:26, 9.26MB/s]\n",
      " 65%|██████▍   | 431M/667M [01:00<00:25, 9.72MB/s]\n",
      " 65%|██████▍   | 432M/667M [01:00<00:25, 9.78MB/s]\n",
      " 65%|██████▍   | 433M/667M [01:00<00:25, 9.56MB/s]\n",
      " 65%|██████▌   | 435M/667M [01:00<00:24, 9.85MB/s]\n",
      " 66%|██████▌   | 437M/667M [01:01<00:23, 10.2MB/s]\n",
      " 66%|██████▌   | 438M/667M [01:01<00:23, 10.2MB/s]\n",
      " 66%|██████▌   | 440M/667M [01:01<00:24, 9.76MB/s]\n",
      " 66%|██████▋   | 442M/667M [01:01<00:27, 8.44MB/s]\n",
      " 66%|██████▋   | 443M/667M [01:01<00:27, 8.48MB/s]\n",
      " 67%|██████▋   | 444M/667M [01:01<00:26, 8.79MB/s]\n",
      " 67%|██████▋   | 445M/667M [01:02<00:26, 8.84MB/s]\n",
      " 67%|██████▋   | 446M/667M [01:02<00:26, 8.72MB/s]\n",
      " 67%|██████▋   | 447M/667M [01:02<00:26, 8.68MB/s]\n",
      " 67%|██████▋   | 448M/667M [01:02<00:26, 8.51MB/s]\n",
      " 67%|██████▋   | 449M/667M [01:02<00:25, 8.80MB/s]\n",
      " 68%|██████▊   | 450M/667M [01:02<00:24, 9.20MB/s]\n",
      " 68%|██████▊   | 451M/667M [01:02<00:23, 9.44MB/s]\n",
      " 68%|██████▊   | 452M/667M [01:02<00:23, 9.62MB/s]\n",
      " 68%|██████▊   | 454M/667M [01:03<00:22, 10.0MB/s]\n",
      " 68%|██████▊   | 456M/667M [01:03<00:21, 10.3MB/s]\n",
      " 69%|██████▊   | 458M/667M [01:03<00:21, 10.2MB/s]\n",
      " 69%|██████▉   | 460M/667M [01:03<00:21, 10.1MB/s]\n",
      " 69%|██████▉   | 462M/667M [01:03<00:20, 10.2MB/s]\n",
      " 69%|██████▉   | 463M/667M [01:04<00:20, 10.3MB/s]\n",
      " 70%|██████▉   | 465M/667M [01:04<00:20, 10.4MB/s]\n",
      " 70%|███████   | 467M/667M [01:04<00:20, 10.3MB/s]\n",
      " 70%|███████   | 468M/667M [01:04<00:20, 9.98MB/s]\n",
      " 70%|███████   | 469M/667M [01:04<00:21, 9.49MB/s]\n",
      " 71%|███████   | 470M/667M [01:04<00:21, 9.49MB/s]\n",
      " 71%|███████   | 471M/667M [01:04<00:21, 9.39MB/s]\n",
      " 71%|███████   | 472M/667M [01:05<00:21, 9.64MB/s]\n",
      " 71%|███████   | 473M/667M [01:05<00:20, 9.71MB/s]\n",
      " 71%|███████   | 474M/667M [01:05<00:21, 9.29MB/s]\n",
      " 71%|███████▏  | 475M/667M [01:05<00:22, 8.93MB/s]\n",
      " 72%|███████▏  | 477M/667M [01:05<00:21, 9.42MB/s]\n",
      " 72%|███████▏  | 478M/667M [01:05<00:21, 9.29MB/s]\n",
      " 72%|███████▏  | 479M/667M [01:05<00:20, 9.56MB/s]\n",
      " 72%|███████▏  | 480M/667M [01:05<00:20, 9.70MB/s]\n",
      " 72%|███████▏  | 481M/667M [01:06<00:19, 9.74MB/s]\n",
      " 72%|███████▏  | 483M/667M [01:06<00:25, 7.53MB/s]\n",
      " 73%|███████▎  | 484M/667M [01:06<00:23, 7.98MB/s]\n",
      " 73%|███████▎  | 485M/667M [01:06<00:22, 8.30MB/s]\n",
      " 73%|███████▎  | 486M/667M [01:06<00:22, 8.42MB/s]\n",
      " 73%|███████▎  | 487M/667M [01:06<00:21, 8.68MB/s]\n",
      " 73%|███████▎  | 489M/667M [01:07<00:20, 9.26MB/s]\n",
      " 74%|███████▎  | 490M/667M [01:07<00:21, 8.45MB/s]\n",
      " 74%|███████▍  | 492M/667M [01:07<00:26, 6.95MB/s]\n",
      " 74%|███████▍  | 493M/667M [01:07<00:26, 6.88MB/s]\n",
      " 74%|███████▍  | 494M/667M [01:07<00:24, 7.44MB/s]\n",
      " 74%|███████▍  | 495M/667M [01:07<00:23, 7.81MB/s]\n",
      " 74%|███████▍  | 496M/667M [01:08<00:21, 8.26MB/s]\n",
      " 75%|███████▍  | 497M/667M [01:08<00:23, 7.58MB/s]\n",
      " 75%|███████▍  | 498M/667M [01:08<00:23, 7.57MB/s]\n",
      " 75%|███████▍  | 499M/667M [01:08<00:22, 7.88MB/s]\n",
      " 75%|███████▌  | 500M/667M [01:08<00:20, 8.45MB/s]\n",
      " 75%|███████▌  | 501M/667M [01:08<00:19, 8.73MB/s]\n",
      " 75%|███████▌  | 502M/667M [01:08<00:19, 8.80MB/s]\n",
      " 75%|███████▌  | 503M/667M [01:08<00:18, 9.11MB/s]\n",
      " 76%|███████▌  | 504M/667M [01:09<00:18, 9.43MB/s]\n",
      " 76%|███████▌  | 505M/667M [01:09<00:18, 9.33MB/s]\n",
      " 76%|███████▌  | 507M/667M [01:09<00:17, 9.81MB/s]\n",
      " 76%|███████▋  | 509M/667M [01:09<00:16, 10.1MB/s]\n",
      " 77%|███████▋  | 511M/667M [01:09<00:15, 10.3MB/s]\n",
      " 77%|███████▋  | 512M/667M [01:09<00:15, 10.3MB/s]\n",
      " 77%|███████▋  | 513M/667M [01:09<00:15, 10.2MB/s]\n",
      " 77%|███████▋  | 514M/667M [01:10<00:16, 9.72MB/s]\n",
      " 77%|███████▋  | 515M/667M [01:10<00:16, 9.45MB/s]\n",
      " 77%|███████▋  | 516M/667M [01:10<00:17, 8.90MB/s]\n",
      " 78%|███████▊  | 517M/667M [01:10<00:23, 6.56MB/s]\n",
      " 78%|███████▊  | 518M/667M [01:10<00:21, 7.25MB/s]\n",
      " 78%|███████▊  | 519M/667M [01:10<00:20, 7.61MB/s]\n",
      " 78%|███████▊  | 520M/667M [01:10<00:19, 7.99MB/s]\n",
      " 78%|███████▊  | 521M/667M [01:11<00:18, 8.37MB/s]\n",
      " 78%|███████▊  | 522M/667M [01:11<00:17, 8.63MB/s]\n",
      " 78%|███████▊  | 523M/667M [01:11<00:20, 7.52MB/s]\n",
      " 79%|███████▊  | 524M/667M [01:11<00:18, 7.96MB/s]\n",
      " 79%|███████▉  | 525M/667M [01:11<00:17, 8.54MB/s]\n",
      " 79%|███████▉  | 526M/667M [01:11<00:16, 8.86MB/s]\n",
      " 79%|███████▉  | 527M/667M [01:11<00:16, 8.99MB/s]\n",
      " 79%|███████▉  | 529M/667M [01:13<00:54, 2.66MB/s]\n",
      " 80%|███████▉  | 530M/667M [01:13<00:44, 3.24MB/s]\n",
      " 80%|███████▉  | 531M/667M [01:13<00:45, 3.10MB/s]\n",
      " 80%|███████▉  | 532M/667M [01:13<00:36, 3.83MB/s]\n",
      " 80%|████████  | 534M/667M [01:13<00:25, 5.36MB/s]\n",
      " 80%|████████  | 536M/667M [01:14<00:20, 6.63MB/s]\n",
      " 81%|████████  | 537M/667M [01:14<00:19, 7.08MB/s]\n",
      " 81%|████████  | 538M/667M [01:14<00:18, 7.46MB/s]\n",
      " 81%|████████  | 540M/667M [01:14<00:20, 6.33MB/s]\n",
      " 81%|████████▏ | 542M/667M [01:15<00:17, 7.36MB/s]\n",
      " 81%|████████▏ | 543M/667M [01:15<00:16, 7.81MB/s]\n",
      " 82%|████████▏ | 545M/667M [01:15<00:15, 8.14MB/s]\n",
      " 82%|████████▏ | 546M/667M [01:15<00:15, 8.41MB/s]\n",
      " 82%|████████▏ | 547M/667M [01:15<00:14, 8.73MB/s]\n",
      " 82%|████████▏ | 548M/667M [01:15<00:13, 8.92MB/s]\n",
      " 82%|████████▏ | 549M/667M [01:15<00:13, 9.26MB/s]\n",
      " 83%|████████▎ | 550M/667M [01:15<00:13, 9.19MB/s]\n",
      " 83%|████████▎ | 551M/667M [01:15<00:13, 9.31MB/s]\n",
      " 83%|████████▎ | 553M/667M [01:16<00:12, 9.81MB/s]\n",
      " 83%|████████▎ | 555M/667M [01:16<00:11, 10.1MB/s]\n",
      " 83%|████████▎ | 556M/667M [01:16<00:11, 9.84MB/s]\n",
      " 84%|████████▎ | 558M/667M [01:16<00:11, 10.0MB/s]\n",
      " 84%|████████▍ | 559M/667M [01:16<00:11, 9.88MB/s]\n",
      " 84%|████████▍ | 560M/667M [01:16<00:11, 9.70MB/s]\n",
      " 84%|████████▍ | 562M/667M [01:17<00:10, 10.0MB/s]\n",
      " 84%|████████▍ | 563M/667M [01:17<00:11, 9.69MB/s]\n",
      " 85%|████████▍ | 564M/667M [01:17<00:11, 9.64MB/s]\n",
      " 85%|████████▍ | 565M/667M [01:17<00:11, 9.25MB/s]\n",
      " 85%|████████▌ | 567M/667M [01:17<00:10, 9.78MB/s]\n",
      " 85%|████████▌ | 568M/667M [01:17<00:10, 9.88MB/s]\n",
      " 85%|████████▌ | 569M/667M [01:17<00:10, 10.0MB/s]\n",
      " 86%|████████▌ | 571M/667M [01:18<00:12, 7.96MB/s]\n",
      " 86%|████████▌ | 572M/667M [01:18<00:12, 8.11MB/s]\n",
      " 86%|████████▌ | 573M/667M [01:19<00:40, 2.45MB/s]\n",
      " 86%|████████▋ | 575M/667M [01:19<00:27, 3.54MB/s]\n",
      " 86%|████████▋ | 576M/667M [01:20<00:23, 4.08MB/s]\n",
      " 87%|████████▋ | 577M/667M [01:20<00:19, 4.77MB/s]\n",
      " 87%|████████▋ | 578M/667M [01:20<00:17, 5.46MB/s]\n",
      " 87%|████████▋ | 579M/667M [01:20<00:14, 6.26MB/s]\n",
      " 87%|████████▋ | 580M/667M [01:20<00:13, 6.90MB/s]\n",
      " 87%|████████▋ | 581M/667M [01:20<00:11, 7.54MB/s]\n",
      " 87%|████████▋ | 582M/667M [01:20<00:11, 7.99MB/s]\n",
      " 87%|████████▋ | 583M/667M [01:20<00:10, 8.38MB/s]\n",
      " 88%|████████▊ | 584M/667M [01:20<00:10, 8.61MB/s]\n",
      " 88%|████████▊ | 585M/667M [01:21<00:10, 8.39MB/s]\n",
      " 88%|████████▊ | 586M/667M [01:21<00:10, 8.22MB/s]\n",
      " 88%|████████▊ | 587M/667M [01:21<00:10, 8.24MB/s]\n",
      " 88%|████████▊ | 588M/667M [01:21<00:10, 8.10MB/s]\n",
      " 88%|████████▊ | 589M/667M [01:21<00:09, 8.21MB/s]\n",
      " 89%|████████▊ | 590M/667M [01:21<00:10, 7.64MB/s]\n",
      " 89%|████████▊ | 591M/667M [01:21<00:10, 7.23MB/s]\n",
      " 89%|████████▉ | 592M/667M [01:22<00:14, 5.51MB/s]\n",
      " 89%|████████▉ | 593M/667M [01:22<00:12, 6.25MB/s]\n",
      " 89%|████████▉ | 594M/667M [01:22<00:10, 7.02MB/s]\n",
      " 89%|████████▉ | 595M/667M [01:22<00:09, 7.61MB/s]\n",
      " 89%|████████▉ | 596M/667M [01:22<00:09, 7.73MB/s]\n",
      " 90%|████████▉ | 597M/667M [01:22<00:09, 7.97MB/s]\n",
      " 90%|████████▉ | 598M/667M [01:22<00:08, 8.41MB/s]\n",
      " 90%|████████▉ | 599M/667M [01:22<00:08, 8.77MB/s]\n",
      " 90%|█████████ | 600M/667M [01:23<00:08, 8.70MB/s]\n",
      " 90%|█████████ | 601M/667M [01:23<00:16, 4.13MB/s]\n",
      " 90%|█████████ | 602M/667M [01:23<00:13, 5.01MB/s]\n",
      " 90%|█████████ | 603M/667M [01:23<00:11, 5.75MB/s]\n",
      " 91%|█████████ | 604M/667M [01:24<00:10, 6.18MB/s]\n",
      " 91%|█████████ | 606M/667M [01:24<00:08, 7.63MB/s]\n",
      " 91%|█████████ | 607M/667M [01:24<00:07, 7.87MB/s]\n",
      " 91%|█████████ | 608M/667M [01:24<00:07, 8.30MB/s]\n",
      " 91%|█████████▏| 609M/667M [01:24<00:08, 7.25MB/s]\n",
      " 92%|█████████▏| 610M/667M [01:24<00:07, 7.79MB/s]\n",
      " 92%|█████████▏| 611M/667M [01:25<00:12, 4.53MB/s]\n",
      " 92%|█████████▏| 612M/667M [01:25<00:10, 5.26MB/s]\n",
      " 92%|█████████▏| 613M/667M [01:25<00:09, 5.97MB/s]\n",
      " 92%|█████████▏| 614M/667M [01:25<00:08, 6.19MB/s]\n",
      " 92%|█████████▏| 615M/667M [01:25<00:07, 6.99MB/s]\n",
      " 92%|█████████▏| 616M/667M [01:25<00:07, 7.47MB/s]\n",
      " 93%|█████████▎| 617M/667M [01:25<00:06, 7.85MB/s]\n",
      " 93%|█████████▎| 618M/667M [01:26<00:06, 8.36MB/s]\n",
      " 93%|█████████▎| 619M/667M [01:27<00:19, 2.58MB/s]\n",
      " 93%|█████████▎| 620M/667M [01:27<00:14, 3.30MB/s]\n",
      " 93%|█████████▎| 622M/667M [01:27<00:09, 4.80MB/s]\n",
      " 93%|█████████▎| 623M/667M [01:27<00:08, 5.54MB/s]\n",
      " 94%|█████████▎| 624M/667M [01:27<00:07, 6.18MB/s]\n",
      " 94%|█████████▍| 625M/667M [01:27<00:06, 6.90MB/s]\n",
      " 94%|█████████▍| 626M/667M [01:27<00:05, 7.55MB/s]\n",
      " 94%|█████████▍| 627M/667M [01:28<00:05, 7.57MB/s]\n",
      " 94%|█████████▍| 628M/667M [01:28<00:05, 7.96MB/s]\n",
      " 94%|█████████▍| 629M/667M [01:28<00:04, 8.35MB/s]\n",
      " 95%|█████████▍| 630M/667M [01:28<00:04, 8.80MB/s]\n",
      " 95%|█████████▍| 631M/667M [01:28<00:04, 9.21MB/s]\n",
      " 95%|█████████▍| 632M/667M [01:28<00:03, 9.55MB/s]\n",
      " 95%|█████████▍| 633M/667M [01:28<00:03, 9.32MB/s]\n",
      " 95%|█████████▌| 635M/667M [01:28<00:03, 8.95MB/s]\n",
      " 95%|█████████▌| 636M/667M [01:29<00:04, 7.95MB/s]\n",
      " 96%|█████████▌| 637M/667M [01:29<00:04, 7.28MB/s]\n",
      " 96%|█████████▌| 638M/667M [01:29<00:03, 7.62MB/s]\n",
      " 96%|█████████▌| 639M/667M [01:29<00:04, 6.61MB/s]\n",
      " 96%|█████████▌| 640M/667M [01:29<00:03, 7.26MB/s]\n",
      " 96%|█████████▌| 641M/667M [01:29<00:03, 7.87MB/s]\n",
      " 96%|█████████▋| 642M/667M [01:29<00:03, 8.49MB/s]\n",
      " 96%|█████████▋| 643M/667M [01:30<00:02, 8.64MB/s]\n",
      " 97%|█████████▋| 645M/667M [01:30<00:02, 9.40MB/s]\n",
      " 97%|█████████▋| 646M/667M [01:30<00:02, 9.31MB/s]\n",
      " 97%|█████████▋| 647M/667M [01:30<00:02, 9.04MB/s]\n",
      " 97%|█████████▋| 649M/667M [01:30<00:01, 9.65MB/s]\n",
      " 98%|█████████▊| 650M/667M [01:30<00:02, 7.39MB/s]\n",
      " 98%|█████████▊| 652M/667M [01:31<00:03, 4.97MB/s]\n",
      " 98%|█████████▊| 653M/667M [01:31<00:02, 5.57MB/s]\n",
      " 98%|█████████▊| 655M/667M [01:31<00:01, 6.83MB/s]\n",
      " 98%|█████████▊| 656M/667M [01:31<00:01, 7.21MB/s]\n",
      " 99%|█████████▊| 658M/667M [01:32<00:01, 7.96MB/s]\n",
      " 99%|█████████▉| 660M/667M [01:32<00:00, 7.73MB/s]\n",
      " 99%|█████████▉| 661M/667M [01:32<00:00, 8.05MB/s]\n",
      " 99%|█████████▉| 663M/667M [01:32<00:00, 8.55MB/s]\n",
      "100%|█████████▉| 664M/667M [01:32<00:00, 8.85MB/s]\n",
      "100%|█████████▉| 665M/667M [01:33<00:00, 8.87MB/s]\n",
      "100%|██████████| 667M/667M [01:33<00:00, 9.46MB/s]\n",
      "100%|██████████| 667M/667M [01:33<00:00, 7.50MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Follow the tutorial in this page:\n",
    "# https://www.endtoend.ai/tutorial/how-to-download-kaggle-datasets-on-ubuntu/\n",
    "!cat ~/.kaggle/kaggle.json\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c datalab-cup3-reverse-image-caption-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# zipfile example\n",
    "def zip_list(file_path):\n",
    "    zf = zipfile.ZipFile(file_path, 'r')\n",
    "    zf.extractall('./')\n",
    "\n",
    "file_path = './datalab-cup3-reverse-image-caption-2021.zip'\n",
    "zip_list(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Packages Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disable warnings, info and errors \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 30 18:40:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.41       Driver Version: 471.41       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 28%   36C    P8    13W / 120W |    974MiB /  6144MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1500    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      2296    C+G   ...ll\\1.0.0.357\\LineCall.exe    N/A      |\n",
      "|    0   N/A  N/A      5364    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A      6764    C+G   ...ype for Desktop\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A      7360    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A      8056    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n",
      "|    0   N/A  N/A      8124    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A      8136    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A      8196    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9068    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A      9824    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A      9896    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11036    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11704    C+G   ...ype for Desktop\\Skype.exe    N/A      |\n",
      "|    0   N/A  N/A     12120    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     12924    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     13512    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
      "|    0   N/A  N/A     14872    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     17916    C+G   ...LINE\\bin\\current\\LINE.exe    N/A      |\n",
      "|    0   N/A  N/A     18176    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     21008    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     21216    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        #for gpu in gpus:\n",
    "        #    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocseeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 5427 vocabularies in total\n",
      "Word to id mapping, for example: flower -> 1\n",
      "Id to word mapping, for example: 1 -> flower\n",
      "Tokens: <PAD>: 5427; <RARE>: 5428\n"
     ]
    }
   ],
   "source": [
    "dictionary_path = './dictionary'\n",
    "vocab = np.load(dictionary_path + '/vocab.npy')\n",
    "print('there are {} vocabularies in total'.format(len(vocab)))\n",
    "\n",
    "word2Id_dict = dict(np.load(dictionary_path + '/word2Id.npy'))\n",
    "id2word_dict = dict(np.load(dictionary_path + '/id2Word.npy'))\n",
    "print('Word to id mapping, for example: %s -> %s' % ('flower', word2Id_dict['flower']))\n",
    "print('Id to word mapping, for example: %s -> %s' % ('1', id2word_dict['1']))\n",
    "print('Tokens: <PAD>: %s; <RARE>: %s' % (word2Id_dict['<PAD>'], word2Id_dict['<RARE>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the flower shown has yellow anther red pistil and bright red petals.\n",
      "['9', '1', '82', '5', '11', '70', '20', '31', '3', '29', '20', '2', '5427', '5427', '5427', '5427', '5427', '5427', '5427', '5427']\n"
     ]
    }
   ],
   "source": [
    "def sent2IdList(line, MAX_SEQ_LENGTH=20):\n",
    "    MAX_SEQ_LIMIT = MAX_SEQ_LENGTH\n",
    "    padding = 0\n",
    "    \n",
    "    # data preprocessing, remove all puntuation in the texts\n",
    "    prep_line = re.sub('[%s]' % re.escape(string.punctuation), ' ', line.rstrip())\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('-', ' ')\n",
    "    prep_line = prep_line.replace('  ', ' ')\n",
    "    prep_line = prep_line.replace('.', '')\n",
    "    tokens = prep_line.split(' ')\n",
    "    tokens = [\n",
    "        tokens[i] for i in range(len(tokens))\n",
    "        if tokens[i] != ' ' and tokens[i] != ''\n",
    "    ]\n",
    "    l = len(tokens)\n",
    "    padding = MAX_SEQ_LIMIT - l\n",
    "    \n",
    "    # make sure length of each text is equal to MAX_SEQ_LENGTH, and replace the less common word with <RARE> token\n",
    "    for i in range(padding):\n",
    "        tokens.append('<PAD>')\n",
    "    line = [\n",
    "        word2Id_dict[tokens[k]]\n",
    "        if tokens[k] in word2Id_dict else word2Id_dict['<RARE>']\n",
    "        for k in range(len(tokens))\n",
    "    ]\n",
    "\n",
    "    return line\n",
    "\n",
    "text = \"the flower shown has yellow anther red pistil and bright red petals.\"\n",
    "print(text)\n",
    "print(sent2IdList(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7370 image in training data\n"
     ]
    }
   ],
   "source": [
    "data_path = './dataset'\n",
    "df = pd.read_pickle(data_path + '/text2ImgData.pkl')\n",
    "num_training_sample = len(df)\n",
    "n_images_train = num_training_sample\n",
    "print('There are %d image in training data' % (n_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Captions</th>\n",
       "      <th>ImagePath</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>[[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...</td>\n",
       "      <td>./102flowers/image_06734.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>[[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...</td>\n",
       "      <td>./102flowers/image_06736.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>[[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...</td>\n",
       "      <td>./102flowers/image_06737.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>[[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...</td>\n",
       "      <td>./102flowers/image_06738.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>[[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...</td>\n",
       "      <td>./102flowers/image_06739.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Captions  \\\n",
       "ID                                                        \n",
       "6734  [[9, 2, 17, 9, 1, 6, 14, 13, 18, 3, 41, 8, 11,...   \n",
       "6736  [[4, 1, 5, 12, 2, 3, 11, 31, 28, 68, 106, 132,...   \n",
       "6737  [[9, 2, 27, 4, 1, 6, 14, 7, 12, 19, 5427, 5427...   \n",
       "6738  [[9, 1, 5, 8, 54, 16, 38, 7, 12, 116, 325, 3, ...   \n",
       "6739  [[4, 12, 1, 5, 29, 11, 19, 7, 26, 70, 5427, 54...   \n",
       "\n",
       "                         ImagePath  \n",
       "ID                                  \n",
       "6734  ./102flowers/image_06734.jpg  \n",
       "6736  ./102flowers/image_06736.jpg  \n",
       "6737  ./102flowers/image_06737.jpg  \n",
       "6738  ./102flowers/image_06738.jpg  \n",
       "6739  ./102flowers/image_06739.jpg  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this competition, you have to generate image in size 64x64x3\n",
    "IMAGE_HEIGHT = 64\n",
    "IMAGE_WIDTH = 64\n",
    "IMAGE_CHANNEL = 3\n",
    "\n",
    "def training_data_generator(caption, image_path):\n",
    "    # load in the image according to image path\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    caption = tf.cast(caption, tf.int32)\n",
    "\n",
    "    return img, caption\n",
    "\n",
    "def dataset_generator(filenames, batch_size, data_generator):\n",
    "    # load the training data into two NumPy arrays\n",
    "    df = pd.read_pickle(filenames)\n",
    "    captions = df['Captions'].values\n",
    "    caption = []\n",
    "    # each image has 1 to 10 corresponding captions\n",
    "    # we choose one of them randomly for training\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(random.choice(captions[i]))\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int64)\n",
    "    image_path = df['ImagePath'].values\n",
    "    \n",
    "    # assume that each row of `features` corresponds to the same row as `labels`.\n",
    "    assert caption.shape[0] == image_path.shape[0]\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, image_path))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(caption)).batch(batch_size, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "dataset = dataset_generator(data_path + '/text2ImgData.pkl', BATCH_SIZE, training_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparas = {\n",
    "    'MAX_SEQ_LENGTH': 20,                     # maximum sequence length\n",
    "    'EMBED_DIM': 256,                         # word embedding dimension\n",
    "    'VOCAB_SIZE': len(word2Id_dict),          # size of dictionary of captions\n",
    "    'RNN_HIDDEN_SIZE': 128,                   # number of RNN neurons\n",
    "    'Z_DIM': 512,                             # random noise z dimension\n",
    "    'DENSE_DIM': 128,                         # number of neurons in dense layer\n",
    "    'IMAGE_SIZE': [64, 64, 3],                # render image size\n",
    "    'BATCH_SIZE': 64,\n",
    "    'LR': 1e-4,\n",
    "    'LR_DECAY': 0.5,\n",
    "    'BETA_1': 0.5,\n",
    "    'N_EPOCH': 600,\n",
    "    'N_SAMPLE': num_training_sample,          # size of training data\n",
    "    'CHECKPOINTS_DIR': './checkpoints/demo',  # checkpoint path\n",
    "    'PRINT_FREQ': 1                           # printing frequency of loss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditioinal GAN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Encode text (a caption) into hidden representation\n",
    "    input: text, which is a list of ids\n",
    "    output: embedding, or hidden representation of input text in dimension of RNN_HIDDEN_SIZE\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        self.batch_size = self.hparas['BATCH_SIZE']\n",
    "        \n",
    "        # embedding with tensorflow API\n",
    "        self.embedding = layers.Embedding(self.hparas['VOCAB_SIZE'], self.hparas['EMBED_DIM'])\n",
    "        # RNN, here we use GRU cell, another common RNN cell similar to LSTM\n",
    "        self.gru = layers.GRU(self.hparas['RNN_HIDDEN_SIZE'],\n",
    "                              return_sequences=True,\n",
    "                              return_state=True,\n",
    "                              recurrent_initializer='glorot_uniform')\n",
    "    \n",
    "    def call(self, text, hidden):\n",
    "        text = self.embedding(text)\n",
    "        output, state = self.gru(text, initial_state = hidden)\n",
    "        return output[:, -1, :], state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.hparas['BATCH_SIZE'], self.hparas['RNN_HIDDEN_SIZE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Generate fake image based on given text(hidden representation) and noise z\n",
    "    input: text and noise\n",
    "    output: fake image with size 64*64*3\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(Generator, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d1 = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d2 = tf.keras.layers.Dense(64*64*3)\n",
    "        \n",
    "    def call(self, text, noise_z):\n",
    "        text = self.flatten(text)\n",
    "        text = self.d1(text)\n",
    "        text = tf.nn.leaky_relu(text)\n",
    "        \n",
    "        # concatenate input text and random noise\n",
    "        text_concat = tf.concat([noise_z, text], axis=1)\n",
    "        text_concat = self.d2(text_concat)\n",
    "        \n",
    "        logits = tf.reshape(text_concat, [-1, 64, 64, 3])\n",
    "        output = tf.nn.tanh(logits)\n",
    "        \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Differentiate the real and fake image\n",
    "    input: image and corresponding text\n",
    "    output: labels, the real image should be 1, while the fake should be 0\n",
    "    \"\"\"\n",
    "    def __init__(self, hparas):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.hparas = hparas\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.d_text = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d_img = tf.keras.layers.Dense(self.hparas['DENSE_DIM'])\n",
    "        self.d = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, img, text):\n",
    "        text = self.flatten(text)\n",
    "        text = self.d_text(text)\n",
    "        text = tf.nn.leaky_relu(text)\n",
    "        \n",
    "        img = self.flatten(img)\n",
    "        img = self.d_img(img)\n",
    "        img = tf.nn.leaky_relu(img)\n",
    "        \n",
    "        # concatenate image with paired text\n",
    "        img_text = tf.concat([text, img], axis=1)\n",
    "        \n",
    "        logits = self.d(img_text)\n",
    "        output = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        return logits, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = TextEncoder(hparas)\n",
    "generator = Generator(hparas)\n",
    "discriminator = Discriminator(hparas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    # output value of real image should be 1\n",
    "    real_loss = cross_entropy(tf.ones_like(real_logits), real_logits)\n",
    "    # output value of fake image should be 0\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_logits), fake_logits)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    # output value of fake image should be 0\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use seperated optimizers for training generator and discriminator\n",
    "generator_optimizer = tf.keras.optimizers.Adam(hparas['LR'])\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(hparas['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one benefit of tf.train.Checkpoint() API is we can save everything seperately\n",
    "checkpoint_dir = hparas['CHECKPOINTS_DIR']\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 text_encoder=text_encoder,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_image, caption, hidden):\n",
    "    # random noise for generator\n",
    "    noise = tf.random.normal(shape=[hparas['BATCH_SIZE'], hparas['Z_DIM']], mean=0.0, stddev=1.0)\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        text_embed, hidden = text_encoder(caption, hidden)\n",
    "        _, fake_image = generator(text_embed, noise)\n",
    "        real_logits, real_output = discriminator(real_image, text_embed)\n",
    "        fake_logits, fake_output = discriminator(fake_image, text_embed)\n",
    "\n",
    "        g_loss = generator_loss(fake_logits)\n",
    "        d_loss = discriminator_loss(real_logits, fake_logits)\n",
    "\n",
    "    grad_g = gen_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    grad_d = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(grad_g, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(grad_d, discriminator.trainable_variables))\n",
    "    \n",
    "    return g_loss, d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(caption, noise, hidden):\n",
    "    text_embed, hidden = text_encoder(caption, hidden)\n",
    "    _, fake_image = generator(text_embed, noise)\n",
    "    return fake_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1], 3))\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx // size[1]\n",
    "        img[j*h:j*h+h, i*w:i*w+w, :] = image\n",
    "    return img\n",
    "\n",
    "def imsave(images, size, path):\n",
    "    # getting the pixel values between [0, 1] to save it\n",
    "    return plt.imsave(path, merge(images, size)*0.5 + 0.5)\n",
    "\n",
    "def save_images(images, size, image_path):\n",
    "    return imsave(images, size, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(caption, batch_size):\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int64)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(caption)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni = int(np.ceil(np.sqrt(hparas['BATCH_SIZE'])))\n",
    "sample_size = hparas['BATCH_SIZE']\n",
    "sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "sample_sentence = [\"the flower shown has yellow anther red pistil and bright red petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are yellow, white and purple and has dark lines\"] * int(sample_size/ni) + \\\n",
    "                  [\"the petals on this flower are white with a yellow center\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has a lot of small round pink petals.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower is orange in color, and has petals that are ruffled and rounded.\"] * int(sample_size/ni) + \\\n",
    "                  [\"the flower has yellow petals and the center of it is brown.\"] * int(sample_size/ni) + \\\n",
    "                  [\"this flower has petals that are blue and white.\"] * int(sample_size/ni) +\\\n",
    "                  [\"these white flowers have petals that start off white in color and end in a white towards the tips.\"] * int(sample_size/ni)\n",
    "\n",
    "for i, sent in enumerate(sample_sentence):\n",
    "    sample_sentence[i] = sent2IdList(sent)\n",
    "sample_sentence = sample_generator(sample_sentence, hparas['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('samples/demo'):\n",
    "    os.makedirs('samples/demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    # hidden state of RNN\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    steps_per_epoch = int(hparas['N_SAMPLE']/hparas['BATCH_SIZE'])\n",
    "    \n",
    "    for epoch in range(hparas['N_EPOCH']):\n",
    "        g_total_loss = 0\n",
    "        d_total_loss = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        for image, caption in dataset:\n",
    "            g_loss, d_loss = train_step(image, caption, hidden)\n",
    "            g_total_loss += g_loss\n",
    "            d_total_loss += d_loss\n",
    "            \n",
    "        time_tuple = time.localtime()\n",
    "        time_string = time.strftime(\"%m/%d/%Y, %H:%M:%S\", time_tuple)\n",
    "            \n",
    "        print(\"Epoch {}, gen_loss: {:.4f}, disc_loss: {:.4f}\".format(epoch+1,\n",
    "                                                                     g_total_loss/steps_per_epoch,\n",
    "                                                                     d_total_loss/steps_per_epoch))\n",
    "        print('Time for epoch {} is {:.4f} sec'.format(epoch+1, time.time()-start))\n",
    "        \n",
    "        # save the model\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "        \n",
    "        # visualization\n",
    "        if (epoch + 1) % hparas['PRINT_FREQ'] == 0:\n",
    "            for caption in sample_sentence:\n",
    "                fake_image = test_step(caption, sample_seed, hidden)\n",
    "            save_images(fake_image, [ni, ni], 'samples/demo/train_{:02d}.jpg'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, gen_loss: 0.4310, disc_loss: 1.1555\n",
      "Time for epoch 1 is 25.1757 sec\n",
      "Epoch 2, gen_loss: 0.4621, disc_loss: 1.1054\n",
      "Time for epoch 2 is 15.8144 sec\n",
      "Epoch 3, gen_loss: 0.6559, disc_loss: 0.8819\n",
      "Time for epoch 3 is 15.0755 sec\n",
      "Epoch 4, gen_loss: 1.0678, disc_loss: 0.5661\n",
      "Time for epoch 4 is 15.3680 sec\n",
      "Epoch 5, gen_loss: 1.9700, disc_loss: 0.2013\n",
      "Time for epoch 5 is 17.5647 sec\n",
      "Epoch 6, gen_loss: 1.7112, disc_loss: 0.2640\n",
      "Time for epoch 6 is 16.9062 sec\n",
      "Epoch 7, gen_loss: 2.3302, disc_loss: 0.1525\n",
      "Time for epoch 7 is 15.4493 sec\n",
      "Epoch 8, gen_loss: 2.2645, disc_loss: 0.1622\n",
      "Time for epoch 8 is 14.6188 sec\n",
      "Epoch 9, gen_loss: 2.8868, disc_loss: 0.1188\n",
      "Time for epoch 9 is 15.0282 sec\n",
      "Epoch 10, gen_loss: 3.0099, disc_loss: 0.1280\n",
      "Time for epoch 10 is 18.6856 sec\n",
      "Epoch 11, gen_loss: 2.9333, disc_loss: 0.1612\n",
      "Time for epoch 11 is 16.6095 sec\n",
      "Epoch 12, gen_loss: 3.2571, disc_loss: 0.2044\n",
      "Time for epoch 12 is 16.8553 sec\n",
      "Epoch 13, gen_loss: 3.5831, disc_loss: 0.2511\n",
      "Time for epoch 13 is 16.3240 sec\n",
      "Epoch 14, gen_loss: 3.2943, disc_loss: 0.3465\n",
      "Time for epoch 14 is 18.2952 sec\n",
      "Epoch 15, gen_loss: 3.6325, disc_loss: 0.4252\n",
      "Time for epoch 15 is 13.7870 sec\n",
      "Epoch 16, gen_loss: 3.8827, disc_loss: 0.4597\n",
      "Time for epoch 16 is 13.9638 sec\n",
      "Epoch 17, gen_loss: 3.2260, disc_loss: 0.5226\n",
      "Time for epoch 17 is 13.8058 sec\n",
      "Epoch 18, gen_loss: 2.9200, disc_loss: 0.7166\n",
      "Time for epoch 18 is 13.7420 sec\n",
      "Epoch 19, gen_loss: 2.7901, disc_loss: 0.7382\n",
      "Time for epoch 19 is 16.4969 sec\n",
      "Epoch 20, gen_loss: 2.8737, disc_loss: 0.6394\n",
      "Time for epoch 20 is 13.7754 sec\n",
      "Epoch 21, gen_loss: 2.8641, disc_loss: 0.6111\n",
      "Time for epoch 21 is 13.5982 sec\n",
      "Epoch 22, gen_loss: 2.5332, disc_loss: 0.6765\n",
      "Time for epoch 22 is 13.6557 sec\n",
      "Epoch 23, gen_loss: 2.1882, disc_loss: 0.7973\n",
      "Time for epoch 23 is 15.2128 sec\n",
      "Epoch 24, gen_loss: 2.1174, disc_loss: 0.9185\n",
      "Time for epoch 24 is 14.8305 sec\n",
      "Epoch 25, gen_loss: 2.5224, disc_loss: 0.7381\n",
      "Time for epoch 25 is 13.6728 sec\n",
      "Epoch 26, gen_loss: 2.6389, disc_loss: 0.6194\n",
      "Time for epoch 26 is 13.5186 sec\n",
      "Epoch 27, gen_loss: 2.4499, disc_loss: 0.7028\n",
      "Time for epoch 27 is 13.6311 sec\n",
      "Epoch 28, gen_loss: 2.5259, disc_loss: 0.6277\n",
      "Time for epoch 28 is 16.4411 sec\n",
      "Epoch 29, gen_loss: 2.1263, disc_loss: 0.7622\n",
      "Time for epoch 29 is 14.2953 sec\n",
      "Epoch 30, gen_loss: 2.1557, disc_loss: 0.6880\n",
      "Time for epoch 30 is 14.1011 sec\n",
      "Epoch 31, gen_loss: 2.2763, disc_loss: 0.6927\n",
      "Time for epoch 31 is 13.9369 sec\n",
      "Epoch 32, gen_loss: 1.9990, disc_loss: 0.8986\n",
      "Time for epoch 32 is 14.1944 sec\n",
      "Epoch 33, gen_loss: 2.0254, disc_loss: 0.8258\n",
      "Time for epoch 33 is 15.7139 sec\n",
      "Epoch 34, gen_loss: 2.2058, disc_loss: 0.7319\n",
      "Time for epoch 34 is 13.9585 sec\n",
      "Epoch 35, gen_loss: 2.2436, disc_loss: 0.6910\n",
      "Time for epoch 35 is 14.9001 sec\n",
      "Epoch 36, gen_loss: 2.0483, disc_loss: 0.7267\n",
      "Time for epoch 36 is 13.7665 sec\n",
      "Epoch 37, gen_loss: 1.8785, disc_loss: 0.6800\n",
      "Time for epoch 37 is 16.5504 sec\n",
      "Epoch 38, gen_loss: 1.6235, disc_loss: 0.7055\n",
      "Time for epoch 38 is 13.7618 sec\n",
      "Epoch 39, gen_loss: 1.3401, disc_loss: 0.7911\n",
      "Time for epoch 39 is 13.8274 sec\n",
      "Epoch 40, gen_loss: 1.2804, disc_loss: 0.8441\n",
      "Time for epoch 40 is 13.7253 sec\n",
      "Epoch 41, gen_loss: 1.2099, disc_loss: 0.9122\n",
      "Time for epoch 41 is 14.4122 sec\n",
      "Epoch 42, gen_loss: 1.1780, disc_loss: 1.0273\n",
      "Time for epoch 42 is 15.5139 sec\n",
      "Epoch 43, gen_loss: 1.2053, disc_loss: 1.0775\n",
      "Time for epoch 43 is 13.7020 sec\n",
      "Epoch 44, gen_loss: 1.1853, disc_loss: 1.1075\n",
      "Time for epoch 44 is 13.8524 sec\n",
      "Epoch 45, gen_loss: 1.2442, disc_loss: 1.1248\n",
      "Time for epoch 45 is 13.7790 sec\n",
      "Epoch 46, gen_loss: 1.5184, disc_loss: 1.0426\n",
      "Time for epoch 46 is 13.8523 sec\n",
      "Epoch 47, gen_loss: 1.3724, disc_loss: 1.1452\n",
      "Time for epoch 47 is 16.0538 sec\n",
      "Epoch 48, gen_loss: 1.6571, disc_loss: 0.9009\n",
      "Time for epoch 48 is 13.7177 sec\n",
      "Epoch 49, gen_loss: 1.8247, disc_loss: 0.8155\n",
      "Time for epoch 49 is 13.7522 sec\n",
      "Epoch 50, gen_loss: 1.8632, disc_loss: 0.7818\n",
      "Time for epoch 50 is 13.6739 sec\n",
      "Epoch 51, gen_loss: 1.7345, disc_loss: 0.8273\n",
      "Time for epoch 51 is 20.1850 sec\n",
      "Epoch 52, gen_loss: 1.5794, disc_loss: 0.8545\n",
      "Time for epoch 52 is 14.8540 sec\n",
      "Epoch 53, gen_loss: 1.7065, disc_loss: 0.8245\n",
      "Time for epoch 53 is 13.9996 sec\n",
      "Epoch 54, gen_loss: 1.5343, disc_loss: 0.9650\n",
      "Time for epoch 54 is 13.5822 sec\n",
      "Epoch 55, gen_loss: 1.5743, disc_loss: 0.8936\n",
      "Time for epoch 55 is 16.4828 sec\n",
      "Epoch 56, gen_loss: 1.5029, disc_loss: 0.9298\n",
      "Time for epoch 56 is 13.8714 sec\n",
      "Epoch 57, gen_loss: 1.3490, disc_loss: 1.0794\n",
      "Time for epoch 57 is 13.7129 sec\n",
      "Epoch 58, gen_loss: 1.5845, disc_loss: 0.8574\n",
      "Time for epoch 58 is 13.5454 sec\n",
      "Epoch 59, gen_loss: 1.3338, disc_loss: 1.0735\n",
      "Time for epoch 59 is 13.5858 sec\n",
      "Epoch 60, gen_loss: 1.6502, disc_loss: 0.8271\n",
      "Time for epoch 60 is 16.1879 sec\n",
      "Epoch 61, gen_loss: 1.4293, disc_loss: 1.0214\n",
      "Time for epoch 61 is 13.6099 sec\n",
      "Epoch 62, gen_loss: 1.6363, disc_loss: 0.8914\n",
      "Time for epoch 62 is 13.5257 sec\n",
      "Epoch 63, gen_loss: 1.3127, disc_loss: 1.1522\n",
      "Time for epoch 63 is 13.4412 sec\n",
      "Epoch 64, gen_loss: 1.6179, disc_loss: 0.8912\n",
      "Time for epoch 64 is 14.5914 sec\n",
      "Epoch 65, gen_loss: 1.4993, disc_loss: 1.0336\n",
      "Time for epoch 65 is 15.0755 sec\n",
      "Epoch 66, gen_loss: 1.6941, disc_loss: 0.9917\n",
      "Time for epoch 66 is 13.7214 sec\n",
      "Epoch 67, gen_loss: 1.7855, disc_loss: 0.9463\n",
      "Time for epoch 67 is 13.6830 sec\n",
      "Epoch 68, gen_loss: 1.8046, disc_loss: 0.8096\n",
      "Time for epoch 68 is 13.8349 sec\n",
      "Epoch 69, gen_loss: 1.7286, disc_loss: 0.7435\n",
      "Time for epoch 69 is 16.3093 sec\n",
      "Epoch 70, gen_loss: 1.7153, disc_loss: 0.7709\n",
      "Time for epoch 70 is 14.8399 sec\n",
      "Epoch 71, gen_loss: 1.6892, disc_loss: 0.7681\n",
      "Time for epoch 71 is 13.5233 sec\n",
      "Epoch 72, gen_loss: 1.3810, disc_loss: 0.9769\n",
      "Time for epoch 72 is 13.5042 sec\n",
      "Epoch 73, gen_loss: 1.5516, disc_loss: 0.8613\n",
      "Time for epoch 73 is 13.6611 sec\n",
      "Epoch 74, gen_loss: 1.4135, disc_loss: 0.9393\n",
      "Time for epoch 74 is 16.0384 sec\n",
      "Epoch 75, gen_loss: 1.5301, disc_loss: 0.8088\n",
      "Time for epoch 75 is 13.4447 sec\n",
      "Epoch 76, gen_loss: 1.2938, disc_loss: 1.0349\n",
      "Time for epoch 76 is 13.5305 sec\n",
      "Epoch 77, gen_loss: 1.4511, disc_loss: 0.9486\n",
      "Time for epoch 77 is 14.6919 sec\n",
      "Epoch 78, gen_loss: 1.2971, disc_loss: 1.0242\n",
      "Time for epoch 78 is 16.4907 sec\n",
      "Epoch 79, gen_loss: 1.3444, disc_loss: 1.0672\n",
      "Time for epoch 79 is 13.9084 sec\n",
      "Epoch 80, gen_loss: 1.4568, disc_loss: 0.9869\n",
      "Time for epoch 80 is 13.6140 sec\n",
      "Epoch 81, gen_loss: 1.3664, disc_loss: 1.1050\n",
      "Time for epoch 81 is 13.6392 sec\n",
      "Epoch 82, gen_loss: 1.4834, disc_loss: 1.0309\n",
      "Time for epoch 82 is 13.6537 sec\n",
      "Epoch 83, gen_loss: 1.5435, disc_loss: 0.9133\n",
      "Time for epoch 83 is 16.4256 sec\n",
      "Epoch 84, gen_loss: 1.5080, disc_loss: 0.9849\n",
      "Time for epoch 84 is 13.6306 sec\n",
      "Epoch 85, gen_loss: 1.6368, disc_loss: 0.8471\n",
      "Time for epoch 85 is 13.6829 sec\n",
      "Epoch 86, gen_loss: 1.5232, disc_loss: 1.0407\n",
      "Time for epoch 86 is 13.7219 sec\n",
      "Epoch 87, gen_loss: 1.4567, disc_loss: 1.0926\n",
      "Time for epoch 87 is 14.6739 sec\n",
      "Epoch 88, gen_loss: 1.8210, disc_loss: 0.8498\n",
      "Time for epoch 88 is 15.1734 sec\n",
      "Epoch 89, gen_loss: 1.5538, disc_loss: 0.9524\n",
      "Time for epoch 89 is 13.6650 sec\n",
      "Epoch 90, gen_loss: 1.8054, disc_loss: 0.7183\n",
      "Time for epoch 90 is 13.6232 sec\n",
      "Epoch 91, gen_loss: 1.2447, disc_loss: 1.1414\n",
      "Time for epoch 91 is 13.6033 sec\n",
      "Epoch 92, gen_loss: 1.3257, disc_loss: 1.0877\n",
      "Time for epoch 92 is 13.7240 sec\n",
      "Epoch 93, gen_loss: 1.2440, disc_loss: 1.0876\n",
      "Time for epoch 93 is 16.1884 sec\n",
      "Epoch 94, gen_loss: 1.3425, disc_loss: 1.0323\n",
      "Time for epoch 94 is 14.3269 sec\n",
      "Epoch 95, gen_loss: 1.2220, disc_loss: 1.2201\n",
      "Time for epoch 95 is 14.0320 sec\n",
      "Epoch 96, gen_loss: 1.3228, disc_loss: 1.1701\n",
      "Time for epoch 96 is 13.5853 sec\n",
      "Epoch 97, gen_loss: 1.6191, disc_loss: 0.9538\n",
      "Time for epoch 97 is 16.3308 sec\n",
      "Epoch 98, gen_loss: 1.4344, disc_loss: 1.0567\n",
      "Time for epoch 98 is 13.8222 sec\n",
      "Epoch 99, gen_loss: 1.6475, disc_loss: 0.9487\n",
      "Time for epoch 99 is 14.1721 sec\n",
      "Epoch 100, gen_loss: 1.6443, disc_loss: 0.8658\n",
      "Time for epoch 100 is 13.7920 sec\n",
      "Epoch 101, gen_loss: 1.7868, disc_loss: 0.7506\n",
      "Time for epoch 101 is 20.4940 sec\n",
      "Epoch 102, gen_loss: 1.6704, disc_loss: 0.7725\n",
      "Time for epoch 102 is 15.0996 sec\n",
      "Epoch 103, gen_loss: 1.5424, disc_loss: 0.8637\n",
      "Time for epoch 103 is 13.7426 sec\n",
      "Epoch 104, gen_loss: 1.2779, disc_loss: 1.0719\n",
      "Time for epoch 104 is 13.9918 sec\n",
      "Epoch 105, gen_loss: 1.1851, disc_loss: 1.1297\n",
      "Time for epoch 105 is 13.6140 sec\n",
      "Epoch 106, gen_loss: 1.1281, disc_loss: 1.2665\n",
      "Time for epoch 106 is 16.6790 sec\n",
      "Epoch 107, gen_loss: 1.3193, disc_loss: 1.1827\n",
      "Time for epoch 107 is 13.7247 sec\n",
      "Epoch 108, gen_loss: 1.3227, disc_loss: 1.1023\n",
      "Time for epoch 108 is 13.6191 sec\n",
      "Epoch 109, gen_loss: 1.4698, disc_loss: 0.8989\n",
      "Time for epoch 109 is 13.5902 sec\n",
      "Epoch 110, gen_loss: 1.3693, disc_loss: 1.1125\n",
      "Time for epoch 110 is 14.8399 sec\n",
      "Epoch 111, gen_loss: 1.5050, disc_loss: 0.8785\n",
      "Time for epoch 111 is 14.8661 sec\n",
      "Epoch 112, gen_loss: 1.4812, disc_loss: 0.9852\n",
      "Time for epoch 112 is 13.5536 sec\n",
      "Epoch 113, gen_loss: 1.4167, disc_loss: 1.0980\n",
      "Time for epoch 113 is 13.6760 sec\n",
      "Epoch 114, gen_loss: 1.5898, disc_loss: 0.8633\n",
      "Time for epoch 114 is 13.5528 sec\n",
      "Epoch 115, gen_loss: 1.3480, disc_loss: 1.1126\n",
      "Time for epoch 115 is 16.3106 sec\n",
      "Epoch 116, gen_loss: 1.4906, disc_loss: 1.1403\n",
      "Time for epoch 116 is 13.7345 sec\n",
      "Epoch 117, gen_loss: 1.3920, disc_loss: 1.0249\n",
      "Time for epoch 117 is 13.5773 sec\n",
      "Epoch 118, gen_loss: 1.5615, disc_loss: 1.0825\n",
      "Time for epoch 118 is 13.8931 sec\n",
      "Epoch 119, gen_loss: 1.4882, disc_loss: 1.0191\n",
      "Time for epoch 119 is 13.5569 sec\n",
      "Epoch 120, gen_loss: 1.6347, disc_loss: 0.9243\n",
      "Time for epoch 120 is 16.4806 sec\n",
      "Epoch 121, gen_loss: 1.4526, disc_loss: 0.9263\n",
      "Time for epoch 121 is 13.4445 sec\n",
      "Epoch 122, gen_loss: 1.8414, disc_loss: 0.7368\n",
      "Time for epoch 122 is 13.4987 sec\n",
      "Epoch 123, gen_loss: 1.3849, disc_loss: 0.9896\n",
      "Time for epoch 123 is 13.4926 sec\n",
      "Epoch 124, gen_loss: 1.3551, disc_loss: 1.1220\n",
      "Time for epoch 124 is 15.4995 sec\n",
      "Epoch 125, gen_loss: 1.2852, disc_loss: 1.0892\n",
      "Time for epoch 125 is 14.0567 sec\n",
      "Epoch 126, gen_loss: 1.1823, disc_loss: 1.1942\n",
      "Time for epoch 126 is 13.5732 sec\n",
      "Epoch 127, gen_loss: 1.3418, disc_loss: 1.0597\n",
      "Time for epoch 127 is 13.6442 sec\n",
      "Epoch 128, gen_loss: 1.2063, disc_loss: 1.1126\n",
      "Time for epoch 128 is 13.4544 sec\n",
      "Epoch 129, gen_loss: 1.4270, disc_loss: 0.9847\n",
      "Time for epoch 129 is 16.3495 sec\n",
      "Epoch 130, gen_loss: 1.4770, disc_loss: 1.0363\n",
      "Time for epoch 130 is 13.5442 sec\n",
      "Epoch 131, gen_loss: 1.5695, disc_loss: 1.0330\n",
      "Time for epoch 131 is 13.5522 sec\n",
      "Epoch 132, gen_loss: 1.5483, disc_loss: 1.0786\n",
      "Time for epoch 132 is 13.5332 sec\n",
      "Epoch 133, gen_loss: 1.6809, disc_loss: 0.8866\n",
      "Time for epoch 133 is 14.7127 sec\n",
      "Epoch 134, gen_loss: 1.3650, disc_loss: 1.0345\n",
      "Time for epoch 134 is 14.8468 sec\n",
      "Epoch 135, gen_loss: 1.4527, disc_loss: 1.0188\n",
      "Time for epoch 135 is 13.4054 sec\n",
      "Epoch 136, gen_loss: 1.4047, disc_loss: 1.0792\n",
      "Time for epoch 136 is 13.5126 sec\n",
      "Epoch 137, gen_loss: 1.4623, disc_loss: 1.0029\n",
      "Time for epoch 137 is 13.5209 sec\n",
      "Epoch 138, gen_loss: 1.2535, disc_loss: 1.1134\n",
      "Time for epoch 138 is 14.0003 sec\n",
      "Epoch 139, gen_loss: 1.5342, disc_loss: 0.9325\n",
      "Time for epoch 139 is 15.4123 sec\n",
      "Epoch 140, gen_loss: 1.2691, disc_loss: 1.1818\n",
      "Time for epoch 140 is 13.5678 sec\n",
      "Epoch 141, gen_loss: 1.5885, disc_loss: 0.9418\n",
      "Time for epoch 141 is 13.7537 sec\n",
      "Epoch 142, gen_loss: 1.1151, disc_loss: 1.2997\n",
      "Time for epoch 142 is 15.0069 sec\n",
      "Epoch 143, gen_loss: 1.6557, disc_loss: 0.8894\n",
      "Time for epoch 143 is 17.3111 sec\n",
      "Epoch 144, gen_loss: 1.1563, disc_loss: 1.3762\n",
      "Time for epoch 144 is 13.7899 sec\n",
      "Epoch 145, gen_loss: 1.5266, disc_loss: 1.0006\n",
      "Time for epoch 145 is 13.5147 sec\n",
      "Epoch 146, gen_loss: 1.1422, disc_loss: 1.3621\n",
      "Time for epoch 146 is 13.4900 sec\n",
      "Epoch 147, gen_loss: 1.3655, disc_loss: 1.1338\n",
      "Time for epoch 147 is 14.4843 sec\n",
      "Epoch 148, gen_loss: 1.5539, disc_loss: 1.0177\n",
      "Time for epoch 148 is 15.1475 sec\n",
      "Epoch 149, gen_loss: 1.4057, disc_loss: 1.0790\n",
      "Time for epoch 149 is 13.5544 sec\n",
      "Epoch 150, gen_loss: 1.6370, disc_loss: 0.9173\n",
      "Time for epoch 150 is 13.5709 sec\n",
      "Epoch 151, gen_loss: 1.4677, disc_loss: 0.9945\n",
      "Time for epoch 151 is 18.5971 sec\n",
      "Epoch 152, gen_loss: 1.2442, disc_loss: 1.2432\n",
      "Time for epoch 152 is 16.5001 sec\n",
      "Epoch 153, gen_loss: 1.3175, disc_loss: 1.1562\n",
      "Time for epoch 153 is 13.5719 sec\n",
      "Epoch 154, gen_loss: 1.4338, disc_loss: 1.0615\n",
      "Time for epoch 154 is 13.9256 sec\n",
      "Epoch 155, gen_loss: 1.5400, disc_loss: 0.9854\n",
      "Time for epoch 155 is 13.5240 sec\n",
      "Epoch 156, gen_loss: 1.6731, disc_loss: 0.9191\n",
      "Time for epoch 156 is 16.2937 sec\n",
      "Epoch 157, gen_loss: 1.5525, disc_loss: 0.9522\n",
      "Time for epoch 157 is 13.4939 sec\n",
      "Epoch 158, gen_loss: 1.4730, disc_loss: 1.0718\n",
      "Time for epoch 158 is 13.5898 sec\n",
      "Epoch 159, gen_loss: 1.5542, disc_loss: 1.0047\n",
      "Time for epoch 159 is 13.4722 sec\n",
      "Epoch 160, gen_loss: 1.4677, disc_loss: 1.1352\n",
      "Time for epoch 160 is 13.6122 sec\n",
      "Epoch 161, gen_loss: 1.6347, disc_loss: 0.9633\n",
      "Time for epoch 161 is 16.0471 sec\n",
      "Epoch 162, gen_loss: 1.4206, disc_loss: 1.0772\n",
      "Time for epoch 162 is 13.6141 sec\n",
      "Epoch 163, gen_loss: 1.6019, disc_loss: 0.9054\n",
      "Time for epoch 163 is 13.6726 sec\n",
      "Epoch 164, gen_loss: 1.2896, disc_loss: 1.1457\n",
      "Time for epoch 164 is 13.4994 sec\n",
      "Epoch 165, gen_loss: 1.6594, disc_loss: 0.8221\n",
      "Time for epoch 165 is 16.2398 sec\n",
      "Epoch 166, gen_loss: 1.1626, disc_loss: 1.2154\n",
      "Time for epoch 166 is 13.6069 sec\n",
      "Epoch 167, gen_loss: 1.3437, disc_loss: 1.0412\n",
      "Time for epoch 167 is 13.4866 sec\n",
      "Epoch 168, gen_loss: 1.1434, disc_loss: 1.2774\n",
      "Time for epoch 168 is 13.5708 sec\n",
      "Epoch 169, gen_loss: 1.2386, disc_loss: 1.2329\n",
      "Time for epoch 169 is 13.7026 sec\n",
      "Epoch 170, gen_loss: 1.3677, disc_loss: 1.1448\n",
      "Time for epoch 170 is 16.3983 sec\n",
      "Epoch 171, gen_loss: 1.2934, disc_loss: 1.2389\n",
      "Time for epoch 171 is 13.5454 sec\n",
      "Epoch 172, gen_loss: 1.4266, disc_loss: 1.0751\n",
      "Time for epoch 172 is 13.5092 sec\n",
      "Epoch 173, gen_loss: 1.5176, disc_loss: 0.9919\n",
      "Time for epoch 173 is 13.5644 sec\n",
      "Epoch 174, gen_loss: 1.5033, disc_loss: 0.9630\n",
      "Time for epoch 174 is 14.4402 sec\n",
      "Epoch 175, gen_loss: 1.5151, disc_loss: 0.9356\n",
      "Time for epoch 175 is 15.0195 sec\n",
      "Epoch 176, gen_loss: 1.4552, disc_loss: 1.0456\n",
      "Time for epoch 176 is 13.5710 sec\n",
      "Epoch 177, gen_loss: 1.3907, disc_loss: 0.9841\n",
      "Time for epoch 177 is 13.5038 sec\n",
      "Epoch 178, gen_loss: 1.3747, disc_loss: 0.9941\n",
      "Time for epoch 178 is 13.5630 sec\n",
      "Epoch 179, gen_loss: 1.0769, disc_loss: 1.3360\n",
      "Time for epoch 179 is 16.2883 sec\n",
      "Epoch 180, gen_loss: 1.3278, disc_loss: 1.1890\n",
      "Time for epoch 180 is 13.4406 sec\n",
      "Epoch 181, gen_loss: 1.1635, disc_loss: 1.4820\n",
      "Time for epoch 181 is 13.5633 sec\n",
      "Epoch 182, gen_loss: 1.4024, disc_loss: 1.2755\n",
      "Time for epoch 182 is 13.5352 sec\n",
      "Epoch 183, gen_loss: 1.8277, disc_loss: 0.9802\n",
      "Time for epoch 183 is 13.5337 sec\n",
      "Epoch 184, gen_loss: 1.5942, disc_loss: 1.1705\n",
      "Time for epoch 184 is 16.3082 sec\n",
      "Epoch 185, gen_loss: 1.9070, disc_loss: 0.9066\n",
      "Time for epoch 185 is 13.4860 sec\n",
      "Epoch 186, gen_loss: 1.8541, disc_loss: 0.8343\n",
      "Time for epoch 186 is 13.6221 sec\n",
      "Epoch 187, gen_loss: 2.0247, disc_loss: 0.6929\n",
      "Time for epoch 187 is 13.4864 sec\n",
      "Epoch 188, gen_loss: 1.4687, disc_loss: 0.9162\n",
      "Time for epoch 188 is 15.0158 sec\n",
      "Epoch 189, gen_loss: 1.7262, disc_loss: 0.7203\n",
      "Time for epoch 189 is 14.6164 sec\n",
      "Epoch 190, gen_loss: 1.1482, disc_loss: 1.1841\n",
      "Time for epoch 190 is 13.6431 sec\n",
      "Epoch 191, gen_loss: 1.2190, disc_loss: 1.1158\n",
      "Time for epoch 191 is 13.5574 sec\n",
      "Epoch 192, gen_loss: 1.2316, disc_loss: 1.1845\n",
      "Time for epoch 192 is 13.5194 sec\n",
      "Epoch 193, gen_loss: 1.2001, disc_loss: 1.2165\n",
      "Time for epoch 193 is 16.2581 sec\n",
      "Epoch 194, gen_loss: 1.0874, disc_loss: 1.3768\n",
      "Time for epoch 194 is 13.5297 sec\n",
      "Epoch 195, gen_loss: 1.3528, disc_loss: 1.1884\n",
      "Time for epoch 195 is 13.4575 sec\n",
      "Epoch 196, gen_loss: 1.3340, disc_loss: 1.1933\n",
      "Time for epoch 196 is 13.5308 sec\n",
      "Epoch 197, gen_loss: 1.6574, disc_loss: 1.0037\n",
      "Time for epoch 197 is 13.6488 sec\n",
      "Epoch 198, gen_loss: 1.3093, disc_loss: 1.0866\n",
      "Time for epoch 198 is 15.9455 sec\n",
      "Epoch 199, gen_loss: 1.4912, disc_loss: 0.8771\n",
      "Time for epoch 199 is 13.5148 sec\n",
      "Epoch 200, gen_loss: 1.4612, disc_loss: 1.0200\n",
      "Time for epoch 200 is 13.4670 sec\n",
      "Epoch 201, gen_loss: 1.1748, disc_loss: 1.4081\n",
      "Time for epoch 201 is 19.2130 sec\n",
      "Epoch 202, gen_loss: 1.4342, disc_loss: 1.2435\n",
      "Time for epoch 202 is 16.3262 sec\n",
      "Epoch 203, gen_loss: 1.4467, disc_loss: 1.2023\n",
      "Time for epoch 203 is 13.8070 sec\n",
      "Epoch 204, gen_loss: 1.5925, disc_loss: 1.1613\n",
      "Time for epoch 204 is 13.8087 sec\n",
      "Epoch 205, gen_loss: 2.0201, disc_loss: 0.9078\n",
      "Time for epoch 205 is 13.6124 sec\n",
      "Epoch 206, gen_loss: 1.9789, disc_loss: 0.7981\n",
      "Time for epoch 206 is 16.3107 sec\n",
      "Epoch 207, gen_loss: 1.7532, disc_loss: 0.8837\n",
      "Time for epoch 207 is 13.4848 sec\n",
      "Epoch 208, gen_loss: 1.3286, disc_loss: 1.0485\n",
      "Time for epoch 208 is 13.4984 sec\n",
      "Epoch 209, gen_loss: 1.4552, disc_loss: 1.1025\n",
      "Time for epoch 209 is 13.4489 sec\n",
      "Epoch 210, gen_loss: 1.0795, disc_loss: 1.4509\n",
      "Time for epoch 210 is 13.6352 sec\n",
      "Epoch 211, gen_loss: 1.6440, disc_loss: 0.9542\n",
      "Time for epoch 211 is 16.1984 sec\n",
      "Epoch 212, gen_loss: 1.1767, disc_loss: 1.3692\n",
      "Time for epoch 212 is 13.5811 sec\n",
      "Epoch 213, gen_loss: 1.7173, disc_loss: 0.9746\n",
      "Time for epoch 213 is 13.4932 sec\n",
      "Epoch 214, gen_loss: 1.5952, disc_loss: 1.0268\n",
      "Time for epoch 214 is 13.5024 sec\n",
      "Epoch 215, gen_loss: 1.5107, disc_loss: 1.1681\n",
      "Time for epoch 215 is 16.1216 sec\n",
      "Epoch 216, gen_loss: 1.6312, disc_loss: 0.9745\n",
      "Time for epoch 216 is 13.5319 sec\n",
      "Epoch 217, gen_loss: 1.3789, disc_loss: 1.1163\n",
      "Time for epoch 217 is 13.5073 sec\n",
      "Epoch 218, gen_loss: 1.4637, disc_loss: 1.0177\n",
      "Time for epoch 218 is 13.5391 sec\n",
      "Epoch 219, gen_loss: 1.4092, disc_loss: 1.1526\n",
      "Time for epoch 219 is 13.5285 sec\n",
      "Epoch 220, gen_loss: 1.6210, disc_loss: 0.9569\n",
      "Time for epoch 220 is 16.3096 sec\n",
      "Epoch 221, gen_loss: 1.2528, disc_loss: 1.2832\n",
      "Time for epoch 221 is 13.5800 sec\n",
      "Epoch 222, gen_loss: 1.8303, disc_loss: 0.9666\n",
      "Time for epoch 222 is 13.4896 sec\n",
      "Epoch 223, gen_loss: 1.1368, disc_loss: 1.5039\n",
      "Time for epoch 223 is 13.5363 sec\n",
      "Epoch 224, gen_loss: 1.5809, disc_loss: 1.0326\n",
      "Time for epoch 224 is 15.6521 sec\n",
      "Epoch 225, gen_loss: 1.3673, disc_loss: 1.1757\n",
      "Time for epoch 225 is 14.0934 sec\n",
      "Epoch 226, gen_loss: 1.5857, disc_loss: 1.0209\n",
      "Time for epoch 226 is 13.7052 sec\n",
      "Epoch 227, gen_loss: 1.5666, disc_loss: 0.9518\n",
      "Time for epoch 227 is 13.6498 sec\n",
      "Epoch 228, gen_loss: 1.4507, disc_loss: 0.9774\n",
      "Time for epoch 228 is 13.5108 sec\n",
      "Epoch 229, gen_loss: 1.4284, disc_loss: 1.0406\n",
      "Time for epoch 229 is 15.1776 sec\n",
      "Epoch 230, gen_loss: 1.4111, disc_loss: 1.1560\n",
      "Time for epoch 230 is 14.2538 sec\n",
      "Epoch 231, gen_loss: 1.5406, disc_loss: 1.0685\n",
      "Time for epoch 231 is 13.5999 sec\n",
      "Epoch 232, gen_loss: 1.2961, disc_loss: 1.2472\n",
      "Time for epoch 232 is 13.6962 sec\n",
      "Epoch 233, gen_loss: 1.4675, disc_loss: 1.1752\n",
      "Time for epoch 233 is 13.6887 sec\n",
      "Epoch 234, gen_loss: 1.7367, disc_loss: 0.9638\n",
      "Time for epoch 234 is 16.3328 sec\n",
      "Epoch 235, gen_loss: 1.2336, disc_loss: 1.2183\n",
      "Time for epoch 235 is 13.4927 sec\n",
      "Epoch 236, gen_loss: 1.5948, disc_loss: 0.9612\n",
      "Time for epoch 236 is 13.4980 sec\n",
      "Epoch 237, gen_loss: 1.4318, disc_loss: 1.1377\n",
      "Time for epoch 237 is 13.4425 sec\n",
      "Epoch 238, gen_loss: 1.5599, disc_loss: 1.0184\n",
      "Time for epoch 238 is 13.5246 sec\n",
      "Epoch 239, gen_loss: 1.6761, disc_loss: 1.0017\n",
      "Time for epoch 239 is 16.3477 sec\n",
      "Epoch 240, gen_loss: 1.3886, disc_loss: 1.1190\n",
      "Time for epoch 240 is 13.4945 sec\n",
      "Epoch 241, gen_loss: 1.5199, disc_loss: 1.0600\n",
      "Time for epoch 241 is 13.4865 sec\n",
      "Epoch 242, gen_loss: 1.4341, disc_loss: 1.0378\n",
      "Time for epoch 242 is 13.4720 sec\n",
      "Epoch 243, gen_loss: 1.5125, disc_loss: 1.1136\n",
      "Time for epoch 243 is 15.2833 sec\n",
      "Epoch 244, gen_loss: 1.4611, disc_loss: 1.1021\n",
      "Time for epoch 244 is 14.3254 sec\n",
      "Epoch 245, gen_loss: 1.3540, disc_loss: 1.1417\n",
      "Time for epoch 245 is 13.4903 sec\n",
      "Epoch 246, gen_loss: 1.4584, disc_loss: 1.0856\n",
      "Time for epoch 246 is 13.4358 sec\n",
      "Epoch 247, gen_loss: 1.4997, disc_loss: 1.0786\n",
      "Time for epoch 247 is 13.4582 sec\n",
      "Epoch 248, gen_loss: 1.3883, disc_loss: 1.1341\n",
      "Time for epoch 248 is 16.3222 sec\n",
      "Epoch 249, gen_loss: 1.5545, disc_loss: 1.2085\n",
      "Time for epoch 249 is 13.5016 sec\n",
      "Epoch 250, gen_loss: 1.4264, disc_loss: 1.1938\n",
      "Time for epoch 250 is 13.5533 sec\n",
      "Epoch 251, gen_loss: 1.5372, disc_loss: 1.1689\n",
      "Time for epoch 251 is 19.2154 sec\n",
      "Epoch 252, gen_loss: 1.6473, disc_loss: 1.1070\n",
      "Time for epoch 252 is 16.4875 sec\n",
      "Epoch 253, gen_loss: 1.8253, disc_loss: 0.8722\n",
      "Time for epoch 253 is 13.5411 sec\n",
      "Epoch 254, gen_loss: 1.6958, disc_loss: 0.9837\n",
      "Time for epoch 254 is 13.7035 sec\n",
      "Epoch 255, gen_loss: 1.6068, disc_loss: 0.9964\n",
      "Time for epoch 255 is 13.5053 sec\n",
      "Epoch 256, gen_loss: 1.4724, disc_loss: 1.1040\n",
      "Time for epoch 256 is 14.3095 sec\n",
      "Epoch 257, gen_loss: 1.7381, disc_loss: 1.0504\n",
      "Time for epoch 257 is 15.2051 sec\n",
      "Epoch 258, gen_loss: 1.4543, disc_loss: 1.1498\n",
      "Time for epoch 258 is 13.5563 sec\n",
      "Epoch 259, gen_loss: 1.6302, disc_loss: 1.0153\n",
      "Time for epoch 259 is 13.5922 sec\n",
      "Epoch 260, gen_loss: 1.7028, disc_loss: 1.0186\n",
      "Time for epoch 260 is 13.4695 sec\n",
      "Epoch 261, gen_loss: 1.5777, disc_loss: 1.0002\n",
      "Time for epoch 261 is 16.2621 sec\n",
      "Epoch 262, gen_loss: 1.6967, disc_loss: 0.9611\n",
      "Time for epoch 262 is 13.5174 sec\n",
      "Epoch 263, gen_loss: 1.6475, disc_loss: 1.0107\n",
      "Time for epoch 263 is 13.3618 sec\n",
      "Epoch 264, gen_loss: 1.6009, disc_loss: 1.0515\n",
      "Time for epoch 264 is 13.5220 sec\n",
      "Epoch 265, gen_loss: 1.4918, disc_loss: 1.0225\n",
      "Time for epoch 265 is 13.6521 sec\n",
      "Epoch 266, gen_loss: 1.2219, disc_loss: 1.2653\n",
      "Time for epoch 266 is 16.0724 sec\n",
      "Epoch 267, gen_loss: 1.2083, disc_loss: 1.3157\n",
      "Time for epoch 267 is 13.6310 sec\n",
      "Epoch 268, gen_loss: 1.2035, disc_loss: 1.2904\n",
      "Time for epoch 268 is 13.8496 sec\n",
      "Epoch 269, gen_loss: 1.4773, disc_loss: 1.2231\n",
      "Time for epoch 269 is 13.9244 sec\n",
      "Epoch 270, gen_loss: 1.2609, disc_loss: 1.3894\n",
      "Time for epoch 270 is 16.6826 sec\n",
      "Epoch 271, gen_loss: 1.4382, disc_loss: 1.1163\n",
      "Time for epoch 271 is 13.7833 sec\n",
      "Epoch 272, gen_loss: 1.3919, disc_loss: 1.1418\n",
      "Time for epoch 272 is 13.5434 sec\n",
      "Epoch 273, gen_loss: 1.5186, disc_loss: 1.1385\n",
      "Time for epoch 273 is 13.4705 sec\n",
      "Epoch 274, gen_loss: 1.5981, disc_loss: 1.0477\n",
      "Time for epoch 274 is 13.5308 sec\n",
      "Epoch 275, gen_loss: 1.7147, disc_loss: 1.0119\n",
      "Time for epoch 275 is 16.3136 sec\n",
      "Epoch 276, gen_loss: 1.3582, disc_loss: 1.2535\n",
      "Time for epoch 276 is 13.5071 sec\n",
      "Epoch 277, gen_loss: 1.6474, disc_loss: 1.0368\n",
      "Time for epoch 277 is 13.5257 sec\n",
      "Epoch 278, gen_loss: 1.5570, disc_loss: 1.0549\n",
      "Time for epoch 278 is 13.5289 sec\n",
      "Epoch 279, gen_loss: 1.4459, disc_loss: 1.0870\n",
      "Time for epoch 279 is 13.5265 sec\n",
      "Epoch 280, gen_loss: 1.0779, disc_loss: 1.4720\n",
      "Time for epoch 280 is 16.2202 sec\n",
      "Epoch 281, gen_loss: 1.7579, disc_loss: 0.9328\n",
      "Time for epoch 281 is 13.4238 sec\n",
      "Epoch 282, gen_loss: 1.5129, disc_loss: 1.0194\n",
      "Time for epoch 282 is 13.5105 sec\n",
      "Epoch 283, gen_loss: 1.6222, disc_loss: 0.9632\n",
      "Time for epoch 283 is 13.4468 sec\n",
      "Epoch 284, gen_loss: 1.2170, disc_loss: 1.2504\n",
      "Time for epoch 284 is 15.0511 sec\n",
      "Epoch 285, gen_loss: 1.3794, disc_loss: 1.3151\n",
      "Time for epoch 285 is 14.3582 sec\n",
      "Epoch 286, gen_loss: 1.2968, disc_loss: 1.3471\n",
      "Time for epoch 286 is 13.3943 sec\n",
      "Epoch 287, gen_loss: 1.1875, disc_loss: 1.4736\n",
      "Time for epoch 287 is 13.4721 sec\n",
      "Epoch 288, gen_loss: 1.8189, disc_loss: 1.0473\n",
      "Time for epoch 288 is 13.5660 sec\n",
      "Epoch 289, gen_loss: 1.2474, disc_loss: 1.3721\n",
      "Time for epoch 289 is 16.4979 sec\n",
      "Epoch 290, gen_loss: 1.5220, disc_loss: 1.1030\n",
      "Time for epoch 290 is 13.4934 sec\n",
      "Epoch 291, gen_loss: 1.6107, disc_loss: 1.0499\n",
      "Time for epoch 291 is 13.6311 sec\n",
      "Epoch 292, gen_loss: 1.6850, disc_loss: 0.9704\n",
      "Time for epoch 292 is 13.4142 sec\n",
      "Epoch 293, gen_loss: 1.4004, disc_loss: 1.1051\n",
      "Time for epoch 293 is 13.7188 sec\n",
      "Epoch 294, gen_loss: 1.4759, disc_loss: 1.1277\n",
      "Time for epoch 294 is 15.7746 sec\n",
      "Epoch 295, gen_loss: 1.6164, disc_loss: 1.0198\n",
      "Time for epoch 295 is 13.6868 sec\n",
      "Epoch 296, gen_loss: 1.1970, disc_loss: 1.4093\n",
      "Time for epoch 296 is 13.4582 sec\n",
      "Epoch 297, gen_loss: 1.3954, disc_loss: 1.2213\n",
      "Time for epoch 297 is 13.5014 sec\n",
      "Epoch 298, gen_loss: 1.6133, disc_loss: 1.0287\n",
      "Time for epoch 298 is 15.7126 sec\n",
      "Epoch 299, gen_loss: 1.6015, disc_loss: 1.0023\n",
      "Time for epoch 299 is 13.8496 sec\n",
      "Epoch 300, gen_loss: 1.5531, disc_loss: 1.0085\n",
      "Time for epoch 300 is 13.4299 sec\n",
      "Epoch 301, gen_loss: 1.4756, disc_loss: 1.0715\n",
      "Time for epoch 301 is 18.0058 sec\n",
      "Epoch 302, gen_loss: 1.4963, disc_loss: 1.0345\n",
      "Time for epoch 302 is 15.6376 sec\n",
      "Epoch 303, gen_loss: 1.5629, disc_loss: 1.0975\n",
      "Time for epoch 303 is 13.9521 sec\n",
      "Epoch 304, gen_loss: 1.6078, disc_loss: 1.0713\n",
      "Time for epoch 304 is 13.7995 sec\n",
      "Epoch 305, gen_loss: 1.4989, disc_loss: 1.1987\n",
      "Time for epoch 305 is 13.4564 sec\n",
      "Epoch 306, gen_loss: 1.3871, disc_loss: 1.2430\n",
      "Time for epoch 306 is 13.3842 sec\n",
      "Epoch 307, gen_loss: 1.4587, disc_loss: 1.2000\n",
      "Time for epoch 307 is 16.1110 sec\n",
      "Epoch 308, gen_loss: 1.3753, disc_loss: 1.2268\n",
      "Time for epoch 308 is 13.9663 sec\n",
      "Epoch 309, gen_loss: 1.6092, disc_loss: 1.0587\n",
      "Time for epoch 309 is 13.5731 sec\n",
      "Epoch 310, gen_loss: 1.3988, disc_loss: 1.0883\n",
      "Time for epoch 310 is 13.3707 sec\n",
      "Epoch 311, gen_loss: 1.5040, disc_loss: 1.0534\n",
      "Time for epoch 311 is 13.7007 sec\n",
      "Epoch 312, gen_loss: 1.3827, disc_loss: 1.2223\n",
      "Time for epoch 312 is 15.6993 sec\n",
      "Epoch 313, gen_loss: 1.2758, disc_loss: 1.4053\n",
      "Time for epoch 313 is 13.4823 sec\n",
      "Epoch 314, gen_loss: 1.6510, disc_loss: 1.0815\n",
      "Time for epoch 314 is 13.6417 sec\n",
      "Epoch 315, gen_loss: 1.4678, disc_loss: 1.2425\n",
      "Time for epoch 315 is 13.4176 sec\n",
      "Epoch 316, gen_loss: 1.5542, disc_loss: 1.1320\n",
      "Time for epoch 316 is 16.2894 sec\n",
      "Epoch 317, gen_loss: 1.8623, disc_loss: 0.9630\n",
      "Time for epoch 317 is 13.5471 sec\n",
      "Epoch 318, gen_loss: 1.7213, disc_loss: 1.0135\n",
      "Time for epoch 318 is 13.5423 sec\n",
      "Epoch 319, gen_loss: 1.7185, disc_loss: 1.0901\n",
      "Time for epoch 319 is 13.4488 sec\n",
      "Epoch 320, gen_loss: 1.8579, disc_loss: 0.8870\n",
      "Time for epoch 320 is 13.4519 sec\n",
      "Epoch 321, gen_loss: 1.6522, disc_loss: 0.9940\n",
      "Time for epoch 321 is 17.7380 sec\n",
      "Epoch 322, gen_loss: 1.9500, disc_loss: 0.7587\n",
      "Time for epoch 322 is 13.8736 sec\n",
      "Epoch 323, gen_loss: 1.7342, disc_loss: 0.9160\n",
      "Time for epoch 323 is 13.4575 sec\n",
      "Epoch 324, gen_loss: 1.5886, disc_loss: 0.9430\n",
      "Time for epoch 324 is 13.4207 sec\n",
      "Epoch 325, gen_loss: 1.3825, disc_loss: 1.0193\n",
      "Time for epoch 325 is 13.4978 sec\n",
      "Epoch 326, gen_loss: 1.2683, disc_loss: 1.2147\n",
      "Time for epoch 326 is 16.0701 sec\n",
      "Epoch 327, gen_loss: 1.1444, disc_loss: 1.2767\n",
      "Time for epoch 327 is 13.3597 sec\n",
      "Epoch 328, gen_loss: 1.2218, disc_loss: 1.2282\n",
      "Time for epoch 328 is 13.4339 sec\n",
      "Epoch 329, gen_loss: 1.2231, disc_loss: 1.4944\n",
      "Time for epoch 329 is 13.4201 sec\n",
      "Epoch 330, gen_loss: 1.3310, disc_loss: 1.1874\n",
      "Time for epoch 330 is 14.3176 sec\n",
      "Epoch 331, gen_loss: 1.4175, disc_loss: 1.0623\n",
      "Time for epoch 331 is 15.1242 sec\n",
      "Epoch 332, gen_loss: 1.4816, disc_loss: 1.2710\n",
      "Time for epoch 332 is 13.5259 sec\n",
      "Epoch 333, gen_loss: 1.5905, disc_loss: 1.0972\n",
      "Time for epoch 333 is 13.4942 sec\n",
      "Epoch 334, gen_loss: 1.3900, disc_loss: 1.2605\n",
      "Time for epoch 334 is 13.5252 sec\n",
      "Epoch 335, gen_loss: 1.3640, disc_loss: 1.3793\n",
      "Time for epoch 335 is 16.1386 sec\n",
      "Epoch 336, gen_loss: 1.5952, disc_loss: 1.2085\n",
      "Time for epoch 336 is 13.4998 sec\n",
      "Epoch 337, gen_loss: 1.5376, disc_loss: 1.1903\n",
      "Time for epoch 337 is 13.5165 sec\n",
      "Epoch 338, gen_loss: 1.6978, disc_loss: 1.0692\n",
      "Time for epoch 338 is 13.3913 sec\n",
      "Epoch 339, gen_loss: 2.1410, disc_loss: 0.7828\n",
      "Time for epoch 339 is 13.4653 sec\n",
      "Epoch 340, gen_loss: 2.0254, disc_loss: 0.8217\n",
      "Time for epoch 340 is 16.2870 sec\n",
      "Epoch 341, gen_loss: 1.7824, disc_loss: 0.9609\n",
      "Time for epoch 341 is 13.4061 sec\n",
      "Epoch 342, gen_loss: 1.5016, disc_loss: 1.1259\n",
      "Time for epoch 342 is 13.5142 sec\n",
      "Epoch 343, gen_loss: 1.5324, disc_loss: 1.1006\n",
      "Time for epoch 343 is 13.3340 sec\n",
      "Epoch 344, gen_loss: 1.5950, disc_loss: 0.9977\n",
      "Time for epoch 344 is 14.2545 sec\n",
      "Epoch 345, gen_loss: 1.6775, disc_loss: 1.0135\n",
      "Time for epoch 345 is 15.4149 sec\n",
      "Epoch 346, gen_loss: 1.2531, disc_loss: 1.2743\n",
      "Time for epoch 346 is 13.4045 sec\n",
      "Epoch 347, gen_loss: 1.4277, disc_loss: 1.1309\n",
      "Time for epoch 347 is 13.4177 sec\n",
      "Epoch 348, gen_loss: 1.5480, disc_loss: 1.1130\n",
      "Time for epoch 348 is 13.5443 sec\n",
      "Epoch 349, gen_loss: 1.2894, disc_loss: 1.1911\n",
      "Time for epoch 349 is 16.1091 sec\n",
      "Epoch 350, gen_loss: 1.3698, disc_loss: 1.1007\n",
      "Time for epoch 350 is 13.5155 sec\n",
      "Epoch 351, gen_loss: 1.4367, disc_loss: 1.0402\n",
      "Time for epoch 351 is 19.2409 sec\n",
      "Epoch 352, gen_loss: 1.4744, disc_loss: 1.0993\n",
      "Time for epoch 352 is 13.4717 sec\n",
      "Epoch 353, gen_loss: 1.3866, disc_loss: 1.2578\n",
      "Time for epoch 353 is 17.0927 sec\n",
      "Epoch 354, gen_loss: 1.4061, disc_loss: 1.3675\n",
      "Time for epoch 354 is 13.4662 sec\n",
      "Epoch 355, gen_loss: 1.6487, disc_loss: 1.2225\n",
      "Time for epoch 355 is 13.4666 sec\n",
      "Epoch 356, gen_loss: 1.4256, disc_loss: 1.4998\n",
      "Time for epoch 356 is 13.4851 sec\n",
      "Epoch 357, gen_loss: 2.0025, disc_loss: 1.0688\n",
      "Time for epoch 357 is 13.5851 sec\n",
      "Epoch 358, gen_loss: 1.7492, disc_loss: 1.1323\n",
      "Time for epoch 358 is 16.2153 sec\n",
      "Epoch 359, gen_loss: 1.7546, disc_loss: 0.9941\n",
      "Time for epoch 359 is 13.4636 sec\n",
      "Epoch 360, gen_loss: 1.7952, disc_loss: 0.9159\n",
      "Time for epoch 360 is 13.5934 sec\n",
      "Epoch 361, gen_loss: 2.0437, disc_loss: 0.7623\n",
      "Time for epoch 361 is 13.5351 sec\n",
      "Epoch 362, gen_loss: 1.7069, disc_loss: 0.8670\n",
      "Time for epoch 362 is 16.2045 sec\n",
      "Epoch 363, gen_loss: 1.5974, disc_loss: 0.9518\n",
      "Time for epoch 363 is 13.5180 sec\n",
      "Epoch 364, gen_loss: 1.5347, disc_loss: 1.0354\n",
      "Time for epoch 364 is 13.4884 sec\n",
      "Epoch 365, gen_loss: 1.4000, disc_loss: 1.1597\n",
      "Time for epoch 365 is 13.4220 sec\n",
      "Epoch 366, gen_loss: 1.6980, disc_loss: 1.0875\n",
      "Time for epoch 366 is 13.4560 sec\n",
      "Epoch 367, gen_loss: 1.4043, disc_loss: 1.1904\n",
      "Time for epoch 367 is 15.3199 sec\n",
      "Epoch 368, gen_loss: 1.3839, disc_loss: 1.1015\n",
      "Time for epoch 368 is 14.1217 sec\n",
      "Epoch 369, gen_loss: 1.4321, disc_loss: 1.1691\n",
      "Time for epoch 369 is 13.4237 sec\n",
      "Epoch 370, gen_loss: 1.3510, disc_loss: 1.2280\n",
      "Time for epoch 370 is 13.4315 sec\n",
      "Epoch 371, gen_loss: 1.3284, disc_loss: 1.2098\n",
      "Time for epoch 371 is 13.4160 sec\n",
      "Epoch 372, gen_loss: 1.6054, disc_loss: 1.0980\n",
      "Time for epoch 372 is 16.1579 sec\n",
      "Epoch 373, gen_loss: 1.2466, disc_loss: 1.3545\n",
      "Time for epoch 373 is 13.5873 sec\n",
      "Epoch 374, gen_loss: 1.3288, disc_loss: 1.1983\n",
      "Time for epoch 374 is 13.3936 sec\n",
      "Epoch 375, gen_loss: 1.7625, disc_loss: 0.9609\n",
      "Time for epoch 375 is 13.4622 sec\n",
      "Epoch 376, gen_loss: 1.5648, disc_loss: 1.1175\n",
      "Time for epoch 376 is 13.4466 sec\n",
      "Epoch 377, gen_loss: 1.3800, disc_loss: 1.1992\n",
      "Time for epoch 377 is 16.1477 sec\n",
      "Epoch 378, gen_loss: 1.2851, disc_loss: 1.2660\n",
      "Time for epoch 378 is 13.5846 sec\n",
      "Epoch 379, gen_loss: 1.6690, disc_loss: 1.1658\n",
      "Time for epoch 379 is 13.4715 sec\n",
      "Epoch 380, gen_loss: 1.4772, disc_loss: 1.3945\n",
      "Time for epoch 380 is 20.6097 sec\n",
      "Epoch 381, gen_loss: 1.4138, disc_loss: 1.3310\n",
      "Time for epoch 381 is 13.8012 sec\n",
      "Epoch 382, gen_loss: 1.7285, disc_loss: 1.0134\n",
      "Time for epoch 382 is 13.4273 sec\n",
      "Epoch 383, gen_loss: 1.8141, disc_loss: 0.9767\n",
      "Time for epoch 383 is 13.3924 sec\n",
      "Epoch 384, gen_loss: 1.6353, disc_loss: 0.9791\n",
      "Time for epoch 384 is 13.4197 sec\n",
      "Epoch 385, gen_loss: 1.5294, disc_loss: 1.0413\n",
      "Time for epoch 385 is 16.2621 sec\n",
      "Epoch 386, gen_loss: 1.7183, disc_loss: 0.9464\n",
      "Time for epoch 386 is 13.3722 sec\n",
      "Epoch 387, gen_loss: 1.6312, disc_loss: 0.9996\n",
      "Time for epoch 387 is 13.4211 sec\n",
      "Epoch 388, gen_loss: 1.6195, disc_loss: 1.0504\n",
      "Time for epoch 388 is 13.4660 sec\n",
      "Epoch 389, gen_loss: 1.4085, disc_loss: 1.1451\n",
      "Time for epoch 389 is 13.4228 sec\n",
      "Epoch 390, gen_loss: 1.6005, disc_loss: 0.9523\n",
      "Time for epoch 390 is 16.1090 sec\n",
      "Epoch 391, gen_loss: 1.5495, disc_loss: 0.9997\n",
      "Time for epoch 391 is 13.3944 sec\n",
      "Epoch 392, gen_loss: 0.9389, disc_loss: 1.5961\n",
      "Time for epoch 392 is 14.1937 sec\n",
      "Epoch 393, gen_loss: 1.1432, disc_loss: 1.3496\n",
      "Time for epoch 393 is 14.7072 sec\n",
      "Epoch 394, gen_loss: 1.2826, disc_loss: 1.3520\n",
      "Time for epoch 394 is 17.2604 sec\n",
      "Epoch 395, gen_loss: 1.2000, disc_loss: 1.3838\n",
      "Time for epoch 395 is 13.4476 sec\n",
      "Epoch 396, gen_loss: 1.4099, disc_loss: 1.1895\n",
      "Time for epoch 396 is 13.5007 sec\n",
      "Epoch 397, gen_loss: 1.5728, disc_loss: 1.0043\n",
      "Time for epoch 397 is 13.3968 sec\n",
      "Epoch 398, gen_loss: 1.5199, disc_loss: 1.0339\n",
      "Time for epoch 398 is 13.5343 sec\n",
      "Epoch 399, gen_loss: 1.2101, disc_loss: 1.2113\n",
      "Time for epoch 399 is 16.3356 sec\n",
      "Epoch 400, gen_loss: 1.5662, disc_loss: 1.1559\n",
      "Time for epoch 400 is 13.5010 sec\n",
      "Epoch 401, gen_loss: 1.2120, disc_loss: 1.3711\n",
      "Time for epoch 401 is 18.3154 sec\n",
      "Epoch 402, gen_loss: 1.4383, disc_loss: 1.3205\n",
      "Time for epoch 402 is 14.6696 sec\n",
      "Epoch 403, gen_loss: 1.3561, disc_loss: 1.6565\n",
      "Time for epoch 403 is 16.3589 sec\n",
      "Epoch 404, gen_loss: 1.5052, disc_loss: 1.3621\n",
      "Time for epoch 404 is 13.4506 sec\n",
      "Epoch 405, gen_loss: 1.6391, disc_loss: 1.1688\n",
      "Time for epoch 405 is 13.4022 sec\n",
      "Epoch 406, gen_loss: 1.6735, disc_loss: 0.9801\n",
      "Time for epoch 406 is 13.4741 sec\n",
      "Epoch 407, gen_loss: 1.8180, disc_loss: 0.9193\n",
      "Time for epoch 407 is 15.9273 sec\n",
      "Epoch 408, gen_loss: 1.5468, disc_loss: 0.9969\n",
      "Time for epoch 408 is 13.5267 sec\n",
      "Epoch 409, gen_loss: 1.4798, disc_loss: 1.0634\n",
      "Time for epoch 409 is 13.4449 sec\n",
      "Epoch 410, gen_loss: 1.9453, disc_loss: 0.8613\n",
      "Time for epoch 410 is 13.5541 sec\n",
      "Epoch 411, gen_loss: 1.3445, disc_loss: 1.2247\n",
      "Time for epoch 411 is 13.4126 sec\n",
      "Epoch 412, gen_loss: 1.4478, disc_loss: 1.1039\n",
      "Time for epoch 412 is 15.0832 sec\n",
      "Epoch 413, gen_loss: 1.4393, disc_loss: 1.2211\n",
      "Time for epoch 413 is 14.4433 sec\n",
      "Epoch 414, gen_loss: 1.1342, disc_loss: 1.6703\n",
      "Time for epoch 414 is 13.6216 sec\n",
      "Epoch 415, gen_loss: 1.5265, disc_loss: 1.2628\n",
      "Time for epoch 415 is 13.4645 sec\n",
      "Epoch 416, gen_loss: 1.4198, disc_loss: 1.3735\n",
      "Time for epoch 416 is 13.5183 sec\n",
      "Epoch 417, gen_loss: 1.6509, disc_loss: 1.0998\n",
      "Time for epoch 417 is 16.1841 sec\n",
      "Epoch 418, gen_loss: 1.6161, disc_loss: 1.1058\n",
      "Time for epoch 418 is 13.4780 sec\n",
      "Epoch 419, gen_loss: 1.6907, disc_loss: 0.9332\n",
      "Time for epoch 419 is 13.5033 sec\n",
      "Epoch 420, gen_loss: 1.7636, disc_loss: 0.9615\n",
      "Time for epoch 420 is 13.6899 sec\n",
      "Epoch 421, gen_loss: 1.6041, disc_loss: 1.0261\n",
      "Time for epoch 421 is 13.6273 sec\n",
      "Epoch 422, gen_loss: 1.4812, disc_loss: 1.1385\n",
      "Time for epoch 422 is 15.9937 sec\n",
      "Epoch 423, gen_loss: 1.7239, disc_loss: 0.9092\n",
      "Time for epoch 423 is 13.5418 sec\n",
      "Epoch 424, gen_loss: 1.3213, disc_loss: 1.2721\n",
      "Time for epoch 424 is 13.4196 sec\n",
      "Epoch 425, gen_loss: 1.3771, disc_loss: 1.3080\n",
      "Time for epoch 425 is 13.4619 sec\n",
      "Epoch 426, gen_loss: 1.3043, disc_loss: 1.3473\n",
      "Time for epoch 426 is 15.0569 sec\n",
      "Epoch 427, gen_loss: 1.3572, disc_loss: 1.3900\n",
      "Time for epoch 427 is 14.4702 sec\n",
      "Epoch 428, gen_loss: 1.5571, disc_loss: 1.2514\n",
      "Time for epoch 428 is 13.5709 sec\n",
      "Epoch 429, gen_loss: 1.6268, disc_loss: 1.3349\n",
      "Time for epoch 429 is 13.4937 sec\n",
      "Epoch 430, gen_loss: 1.5551, disc_loss: 1.1710\n",
      "Time for epoch 430 is 13.5057 sec\n",
      "Epoch 431, gen_loss: 1.8721, disc_loss: 0.8961\n",
      "Time for epoch 431 is 16.3150 sec\n",
      "Epoch 432, gen_loss: 1.5619, disc_loss: 1.1071\n",
      "Time for epoch 432 is 13.3975 sec\n",
      "Epoch 433, gen_loss: 1.7650, disc_loss: 0.9024\n",
      "Time for epoch 433 is 13.6129 sec\n",
      "Epoch 434, gen_loss: 1.9187, disc_loss: 0.8047\n",
      "Time for epoch 434 is 13.5278 sec\n",
      "Epoch 435, gen_loss: 1.4075, disc_loss: 1.1023\n",
      "Time for epoch 435 is 13.6274 sec\n",
      "Epoch 436, gen_loss: 1.4635, disc_loss: 1.0475\n",
      "Time for epoch 436 is 15.8826 sec\n",
      "Epoch 437, gen_loss: 1.4130, disc_loss: 1.2581\n",
      "Time for epoch 437 is 13.5276 sec\n",
      "Epoch 438, gen_loss: 1.3868, disc_loss: 1.3035\n",
      "Time for epoch 438 is 13.5083 sec\n",
      "Epoch 439, gen_loss: 1.4419, disc_loss: 1.2649\n",
      "Time for epoch 439 is 13.4197 sec\n",
      "Epoch 440, gen_loss: 1.6603, disc_loss: 1.0557\n",
      "Time for epoch 440 is 15.2010 sec\n",
      "Epoch 441, gen_loss: 1.3706, disc_loss: 1.2876\n",
      "Time for epoch 441 is 14.3396 sec\n",
      "Epoch 442, gen_loss: 1.3446, disc_loss: 1.1891\n",
      "Time for epoch 442 is 13.4728 sec\n",
      "Epoch 443, gen_loss: 1.6341, disc_loss: 1.0608\n",
      "Time for epoch 443 is 13.4449 sec\n",
      "Epoch 444, gen_loss: 1.1212, disc_loss: 1.4847\n",
      "Time for epoch 444 is 13.4837 sec\n",
      "Epoch 445, gen_loss: 1.5140, disc_loss: 1.1041\n",
      "Time for epoch 445 is 16.2533 sec\n",
      "Epoch 446, gen_loss: 1.1459, disc_loss: 1.4424\n",
      "Time for epoch 446 is 13.4793 sec\n",
      "Epoch 447, gen_loss: 1.1978, disc_loss: 1.4713\n",
      "Time for epoch 447 is 13.4421 sec\n",
      "Epoch 448, gen_loss: 1.4595, disc_loss: 1.3333\n",
      "Time for epoch 448 is 13.4562 sec\n",
      "Epoch 449, gen_loss: 1.6397, disc_loss: 1.2626\n",
      "Time for epoch 449 is 13.6288 sec\n",
      "Epoch 450, gen_loss: 1.5095, disc_loss: 1.2529\n",
      "Time for epoch 450 is 15.9164 sec\n",
      "Epoch 451, gen_loss: 2.0165, disc_loss: 1.0448\n",
      "Time for epoch 451 is 18.5321 sec\n",
      "Epoch 452, gen_loss: 1.8715, disc_loss: 1.0589\n",
      "Time for epoch 452 is 14.2922 sec\n",
      "Epoch 453, gen_loss: 2.0859, disc_loss: 0.9142\n",
      "Time for epoch 453 is 14.4641 sec\n",
      "Epoch 454, gen_loss: 2.1008, disc_loss: 0.7825\n",
      "Time for epoch 454 is 16.0598 sec\n",
      "Epoch 455, gen_loss: 1.7025, disc_loss: 0.9820\n",
      "Time for epoch 455 is 13.6568 sec\n",
      "Epoch 456, gen_loss: 1.8853, disc_loss: 0.9642\n",
      "Time for epoch 456 is 13.4364 sec\n",
      "Epoch 457, gen_loss: 1.9179, disc_loss: 0.9734\n",
      "Time for epoch 457 is 13.5299 sec\n",
      "Epoch 458, gen_loss: 1.8389, disc_loss: 0.9304\n",
      "Time for epoch 458 is 15.9670 sec\n",
      "Epoch 459, gen_loss: 1.6498, disc_loss: 0.9681\n",
      "Time for epoch 459 is 13.6146 sec\n",
      "Epoch 460, gen_loss: 1.3839, disc_loss: 1.1481\n",
      "Time for epoch 460 is 13.4650 sec\n",
      "Epoch 461, gen_loss: 1.5818, disc_loss: 0.9148\n",
      "Time for epoch 461 is 13.4411 sec\n",
      "Epoch 462, gen_loss: 1.4428, disc_loss: 1.0479\n",
      "Time for epoch 462 is 13.6986 sec\n",
      "Epoch 463, gen_loss: 1.2292, disc_loss: 1.1588\n",
      "Time for epoch 463 is 16.2999 sec\n",
      "Epoch 464, gen_loss: 1.3809, disc_loss: 1.0910\n",
      "Time for epoch 464 is 13.4702 sec\n",
      "Epoch 465, gen_loss: 1.2924, disc_loss: 1.2345\n",
      "Time for epoch 465 is 13.4402 sec\n",
      "Epoch 466, gen_loss: 0.9507, disc_loss: 1.8230\n",
      "Time for epoch 466 is 13.4268 sec\n",
      "Epoch 467, gen_loss: 1.2204, disc_loss: 1.4445\n",
      "Time for epoch 467 is 13.6792 sec\n",
      "Epoch 468, gen_loss: 1.3565, disc_loss: 1.4073\n",
      "Time for epoch 468 is 15.6267 sec\n",
      "Epoch 469, gen_loss: 1.2314, disc_loss: 1.4945\n",
      "Time for epoch 469 is 13.5194 sec\n",
      "Epoch 470, gen_loss: 1.6751, disc_loss: 1.1644\n",
      "Time for epoch 470 is 13.4860 sec\n",
      "Epoch 471, gen_loss: 1.6702, disc_loss: 1.2039\n",
      "Time for epoch 471 is 13.4421 sec\n",
      "Epoch 472, gen_loss: 1.5999, disc_loss: 1.1560\n",
      "Time for epoch 472 is 15.9552 sec\n",
      "Epoch 473, gen_loss: 1.7082, disc_loss: 1.0227\n",
      "Time for epoch 473 is 13.4982 sec\n",
      "Epoch 474, gen_loss: 1.5331, disc_loss: 1.1934\n",
      "Time for epoch 474 is 13.4071 sec\n",
      "Epoch 475, gen_loss: 1.6984, disc_loss: 1.0141\n",
      "Time for epoch 475 is 13.4706 sec\n",
      "Epoch 476, gen_loss: 2.0757, disc_loss: 0.8927\n",
      "Time for epoch 476 is 13.4743 sec\n",
      "Epoch 477, gen_loss: 1.3698, disc_loss: 1.2075\n",
      "Time for epoch 477 is 16.6129 sec\n",
      "Epoch 478, gen_loss: 1.6752, disc_loss: 0.9484\n",
      "Time for epoch 478 is 13.4468 sec\n",
      "Epoch 479, gen_loss: 1.5815, disc_loss: 1.0018\n",
      "Time for epoch 479 is 13.4627 sec\n",
      "Epoch 480, gen_loss: 1.5010, disc_loss: 1.1578\n",
      "Time for epoch 480 is 13.4707 sec\n",
      "Epoch 481, gen_loss: 1.2962, disc_loss: 1.2864\n",
      "Time for epoch 481 is 14.2121 sec\n",
      "Epoch 482, gen_loss: 1.3263, disc_loss: 1.3483\n",
      "Time for epoch 482 is 15.0594 sec\n",
      "Epoch 483, gen_loss: 1.6258, disc_loss: 1.1622\n",
      "Time for epoch 483 is 13.5241 sec\n",
      "Epoch 484, gen_loss: 1.4986, disc_loss: 1.1789\n",
      "Time for epoch 484 is 13.4560 sec\n",
      "Epoch 485, gen_loss: 1.4282, disc_loss: 1.3315\n",
      "Time for epoch 485 is 13.4846 sec\n",
      "Epoch 486, gen_loss: 1.3293, disc_loss: 1.4826\n",
      "Time for epoch 486 is 15.8110 sec\n",
      "Epoch 487, gen_loss: 1.7446, disc_loss: 1.0752\n",
      "Time for epoch 487 is 13.4460 sec\n",
      "Epoch 488, gen_loss: 1.6838, disc_loss: 1.0836\n",
      "Time for epoch 488 is 13.4192 sec\n",
      "Epoch 489, gen_loss: 1.3113, disc_loss: 1.3962\n",
      "Time for epoch 489 is 13.4148 sec\n",
      "Epoch 490, gen_loss: 2.1772, disc_loss: 0.8355\n",
      "Time for epoch 490 is 13.4854 sec\n",
      "Epoch 491, gen_loss: 1.4846, disc_loss: 1.1818\n",
      "Time for epoch 491 is 16.3177 sec\n",
      "Epoch 492, gen_loss: 1.6872, disc_loss: 1.0045\n",
      "Time for epoch 492 is 13.4674 sec\n",
      "Epoch 493, gen_loss: 1.8110, disc_loss: 0.8721\n",
      "Time for epoch 493 is 13.5302 sec\n",
      "Epoch 494, gen_loss: 1.6168, disc_loss: 0.8809\n",
      "Time for epoch 494 is 13.4926 sec\n",
      "Epoch 495, gen_loss: 1.6224, disc_loss: 0.8896\n",
      "Time for epoch 495 is 13.7505 sec\n",
      "Epoch 496, gen_loss: 1.4324, disc_loss: 1.0207\n",
      "Time for epoch 496 is 15.7590 sec\n",
      "Epoch 497, gen_loss: 1.4450, disc_loss: 1.0485\n",
      "Time for epoch 497 is 13.4025 sec\n",
      "Epoch 498, gen_loss: 1.4661, disc_loss: 1.1003\n",
      "Time for epoch 498 is 13.3963 sec\n",
      "Epoch 499, gen_loss: 1.2233, disc_loss: 1.3083\n",
      "Time for epoch 499 is 13.4139 sec\n",
      "Epoch 500, gen_loss: 1.2608, disc_loss: 1.2937\n",
      "Time for epoch 500 is 15.4747 sec\n",
      "Epoch 501, gen_loss: 1.1492, disc_loss: 1.4339\n",
      "Time for epoch 501 is 18.0612 sec\n",
      "Epoch 502, gen_loss: 1.4243, disc_loss: 1.2941\n",
      "Time for epoch 502 is 13.6846 sec\n",
      "Epoch 503, gen_loss: 1.3939, disc_loss: 1.2705\n",
      "Time for epoch 503 is 13.7977 sec\n",
      "Epoch 504, gen_loss: 1.4349, disc_loss: 1.2718\n",
      "Time for epoch 504 is 16.3294 sec\n",
      "Epoch 505, gen_loss: 1.2764, disc_loss: 1.2702\n",
      "Time for epoch 505 is 14.4788 sec\n",
      "Epoch 506, gen_loss: 1.6618, disc_loss: 1.0180\n",
      "Time for epoch 506 is 13.4382 sec\n",
      "Epoch 507, gen_loss: 1.3071, disc_loss: 1.3688\n",
      "Time for epoch 507 is 13.3661 sec\n",
      "Epoch 508, gen_loss: 1.5493, disc_loss: 1.1606\n",
      "Time for epoch 508 is 13.5113 sec\n",
      "Epoch 509, gen_loss: 1.4293, disc_loss: 1.3191\n",
      "Time for epoch 509 is 16.2370 sec\n",
      "Epoch 510, gen_loss: 1.6176, disc_loss: 1.1901\n",
      "Time for epoch 510 is 13.4687 sec\n",
      "Epoch 511, gen_loss: 1.6298, disc_loss: 1.2640\n",
      "Time for epoch 511 is 13.5042 sec\n",
      "Epoch 512, gen_loss: 1.8312, disc_loss: 1.0321\n",
      "Time for epoch 512 is 13.4782 sec\n",
      "Epoch 513, gen_loss: 1.7481, disc_loss: 1.0892\n",
      "Time for epoch 513 is 13.4350 sec\n",
      "Epoch 514, gen_loss: 1.8925, disc_loss: 0.9666\n",
      "Time for epoch 514 is 16.1139 sec\n",
      "Epoch 515, gen_loss: 1.5226, disc_loss: 1.0514\n",
      "Time for epoch 515 is 13.4441 sec\n",
      "Epoch 516, gen_loss: 1.6129, disc_loss: 1.0483\n",
      "Time for epoch 516 is 13.4558 sec\n",
      "Epoch 517, gen_loss: 1.6208, disc_loss: 0.8905\n",
      "Time for epoch 517 is 13.3964 sec\n",
      "Epoch 518, gen_loss: 1.2871, disc_loss: 1.1555\n",
      "Time for epoch 518 is 14.3902 sec\n",
      "Epoch 519, gen_loss: 1.1043, disc_loss: 1.4098\n",
      "Time for epoch 519 is 15.0231 sec\n",
      "Epoch 520, gen_loss: 1.4957, disc_loss: 1.1692\n",
      "Time for epoch 520 is 13.4344 sec\n",
      "Epoch 521, gen_loss: 1.0982, disc_loss: 1.6312\n",
      "Time for epoch 521 is 13.3758 sec\n",
      "Epoch 522, gen_loss: 1.3292, disc_loss: 1.3991\n",
      "Time for epoch 522 is 13.3846 sec\n",
      "Epoch 523, gen_loss: 1.0808, disc_loss: 1.7351\n",
      "Time for epoch 523 is 16.0478 sec\n",
      "Epoch 524, gen_loss: 1.7052, disc_loss: 1.2532\n",
      "Time for epoch 524 is 13.4429 sec\n",
      "Epoch 525, gen_loss: 1.3464, disc_loss: 1.4353\n",
      "Time for epoch 525 is 13.6273 sec\n",
      "Epoch 526, gen_loss: 1.6550, disc_loss: 1.1032\n",
      "Time for epoch 526 is 13.4352 sec\n",
      "Epoch 527, gen_loss: 1.8648, disc_loss: 1.0441\n",
      "Time for epoch 527 is 13.4219 sec\n",
      "Epoch 528, gen_loss: 1.6627, disc_loss: 1.0215\n",
      "Time for epoch 528 is 16.1651 sec\n",
      "Epoch 529, gen_loss: 1.9777, disc_loss: 0.8527\n",
      "Time for epoch 529 is 13.5514 sec\n",
      "Epoch 530, gen_loss: 1.8837, disc_loss: 0.9229\n",
      "Time for epoch 530 is 13.4618 sec\n",
      "Epoch 531, gen_loss: 1.6204, disc_loss: 1.0781\n",
      "Time for epoch 531 is 13.4406 sec\n",
      "Epoch 532, gen_loss: 1.8217, disc_loss: 0.9912\n",
      "Time for epoch 532 is 13.6460 sec\n",
      "Epoch 533, gen_loss: 1.9085, disc_loss: 0.9421\n",
      "Time for epoch 533 is 16.1601 sec\n",
      "Epoch 534, gen_loss: 2.1703, disc_loss: 0.8233\n",
      "Time for epoch 534 is 13.4068 sec\n",
      "Epoch 535, gen_loss: 1.5215, disc_loss: 1.0283\n",
      "Time for epoch 535 is 13.4430 sec\n",
      "Epoch 536, gen_loss: 1.8956, disc_loss: 0.8383\n",
      "Time for epoch 536 is 13.4340 sec\n",
      "Epoch 537, gen_loss: 1.5432, disc_loss: 1.0432\n",
      "Time for epoch 537 is 15.6544 sec\n",
      "Epoch 538, gen_loss: 1.3958, disc_loss: 1.1742\n",
      "Time for epoch 538 is 14.1994 sec\n",
      "Epoch 539, gen_loss: 1.6031, disc_loss: 1.1303\n",
      "Time for epoch 539 is 14.0663 sec\n",
      "Epoch 540, gen_loss: 1.2557, disc_loss: 1.2618\n",
      "Time for epoch 540 is 13.6833 sec\n",
      "Epoch 541, gen_loss: 1.1728, disc_loss: 1.3019\n",
      "Time for epoch 541 is 13.5091 sec\n",
      "Epoch 542, gen_loss: 1.1913, disc_loss: 1.3436\n",
      "Time for epoch 542 is 16.9011 sec\n",
      "Epoch 543, gen_loss: 1.3717, disc_loss: 1.1462\n",
      "Time for epoch 543 is 13.6044 sec\n",
      "Epoch 544, gen_loss: 1.3237, disc_loss: 1.2340\n",
      "Time for epoch 544 is 13.4494 sec\n",
      "Epoch 545, gen_loss: 1.3764, disc_loss: 1.2005\n",
      "Time for epoch 545 is 13.5745 sec\n",
      "Epoch 546, gen_loss: 1.1542, disc_loss: 1.5940\n",
      "Time for epoch 546 is 13.5660 sec\n",
      "Epoch 547, gen_loss: 1.3789, disc_loss: 1.2462\n",
      "Time for epoch 547 is 16.7693 sec\n",
      "Epoch 548, gen_loss: 1.4751, disc_loss: 1.3208\n",
      "Time for epoch 548 is 13.4736 sec\n",
      "Epoch 549, gen_loss: 1.2739, disc_loss: 1.4947\n",
      "Time for epoch 549 is 13.5536 sec\n",
      "Epoch 550, gen_loss: 1.3841, disc_loss: 1.2999\n",
      "Time for epoch 550 is 13.6174 sec\n",
      "Epoch 551, gen_loss: 1.6129, disc_loss: 1.1078\n",
      "Time for epoch 551 is 21.5727 sec\n",
      "Epoch 552, gen_loss: 1.5881, disc_loss: 1.0767\n",
      "Time for epoch 552 is 13.5833 sec\n",
      "Epoch 553, gen_loss: 1.5995, disc_loss: 1.0683\n",
      "Time for epoch 553 is 13.5542 sec\n",
      "Epoch 554, gen_loss: 1.6440, disc_loss: 0.9649\n",
      "Time for epoch 554 is 13.9375 sec\n",
      "Epoch 555, gen_loss: 1.3801, disc_loss: 1.1136\n",
      "Time for epoch 555 is 13.6210 sec\n",
      "Epoch 556, gen_loss: 1.4897, disc_loss: 1.1755\n",
      "Time for epoch 556 is 16.4308 sec\n",
      "Epoch 557, gen_loss: 1.6985, disc_loss: 0.9939\n",
      "Time for epoch 557 is 13.5579 sec\n",
      "Epoch 558, gen_loss: 1.2617, disc_loss: 1.4087\n",
      "Time for epoch 558 is 13.6193 sec\n",
      "Epoch 559, gen_loss: 1.5626, disc_loss: 1.2120\n",
      "Time for epoch 559 is 13.4102 sec\n",
      "Epoch 560, gen_loss: 1.2248, disc_loss: 1.4989\n",
      "Time for epoch 560 is 13.9580 sec\n",
      "Epoch 561, gen_loss: 1.8093, disc_loss: 1.0004\n",
      "Time for epoch 561 is 15.5607 sec\n",
      "Epoch 562, gen_loss: 1.3577, disc_loss: 1.4438\n",
      "Time for epoch 562 is 13.6164 sec\n",
      "Epoch 563, gen_loss: 1.2368, disc_loss: 1.4146\n",
      "Time for epoch 563 is 13.4923 sec\n",
      "Epoch 564, gen_loss: 1.6737, disc_loss: 1.1604\n",
      "Time for epoch 564 is 13.4629 sec\n",
      "Epoch 565, gen_loss: 1.7989, disc_loss: 1.0601\n",
      "Time for epoch 565 is 15.7807 sec\n",
      "Epoch 566, gen_loss: 1.4063, disc_loss: 1.3820\n",
      "Time for epoch 566 is 13.5349 sec\n",
      "Epoch 567, gen_loss: 1.4752, disc_loss: 1.2814\n",
      "Time for epoch 567 is 13.6893 sec\n",
      "Epoch 568, gen_loss: 1.8274, disc_loss: 0.9291\n",
      "Time for epoch 568 is 13.5250 sec\n",
      "Epoch 569, gen_loss: 1.6561, disc_loss: 1.0528\n",
      "Time for epoch 569 is 13.4749 sec\n",
      "Epoch 570, gen_loss: 1.6083, disc_loss: 1.0876\n",
      "Time for epoch 570 is 16.2892 sec\n",
      "Epoch 571, gen_loss: 1.5609, disc_loss: 1.0347\n",
      "Time for epoch 571 is 13.5112 sec\n",
      "Epoch 572, gen_loss: 1.6559, disc_loss: 1.0946\n",
      "Time for epoch 572 is 14.3550 sec\n",
      "Epoch 573, gen_loss: 1.4096, disc_loss: 1.1441\n",
      "Time for epoch 573 is 13.4590 sec\n",
      "Epoch 574, gen_loss: 1.3033, disc_loss: 1.2916\n",
      "Time for epoch 574 is 13.8711 sec\n",
      "Epoch 575, gen_loss: 1.5794, disc_loss: 1.2138\n",
      "Time for epoch 575 is 15.7661 sec\n",
      "Epoch 576, gen_loss: 1.5436, disc_loss: 1.1208\n",
      "Time for epoch 576 is 13.5097 sec\n",
      "Epoch 577, gen_loss: 1.3691, disc_loss: 1.2719\n",
      "Time for epoch 577 is 13.5337 sec\n",
      "Epoch 578, gen_loss: 1.1778, disc_loss: 1.5155\n",
      "Time for epoch 578 is 13.5428 sec\n",
      "Epoch 579, gen_loss: 1.9377, disc_loss: 1.0622\n",
      "Time for epoch 579 is 15.2557 sec\n",
      "Epoch 580, gen_loss: 1.2602, disc_loss: 1.4186\n",
      "Time for epoch 580 is 14.2177 sec\n",
      "Epoch 581, gen_loss: 1.4015, disc_loss: 1.2122\n",
      "Time for epoch 581 is 13.4945 sec\n",
      "Epoch 582, gen_loss: 1.8061, disc_loss: 0.9965\n",
      "Time for epoch 582 is 13.4804 sec\n",
      "Epoch 583, gen_loss: 1.4359, disc_loss: 1.2249\n",
      "Time for epoch 583 is 13.4186 sec\n",
      "Epoch 584, gen_loss: 1.3573, disc_loss: 1.3073\n",
      "Time for epoch 584 is 16.1992 sec\n",
      "Epoch 585, gen_loss: 1.4817, disc_loss: 1.3254\n",
      "Time for epoch 585 is 13.2879 sec\n",
      "Epoch 586, gen_loss: 1.5685, disc_loss: 1.1890\n",
      "Time for epoch 586 is 13.4426 sec\n",
      "Epoch 587, gen_loss: 1.8153, disc_loss: 1.0077\n",
      "Time for epoch 587 is 13.3781 sec\n",
      "Epoch 588, gen_loss: 1.6938, disc_loss: 1.0089\n",
      "Time for epoch 588 is 13.5847 sec\n",
      "Epoch 589, gen_loss: 1.2332, disc_loss: 1.2809\n",
      "Time for epoch 589 is 16.3270 sec\n",
      "Epoch 590, gen_loss: 1.8763, disc_loss: 0.8329\n",
      "Time for epoch 590 is 13.4412 sec\n",
      "Epoch 591, gen_loss: 1.7196, disc_loss: 0.9968\n",
      "Time for epoch 591 is 13.4183 sec\n",
      "Epoch 592, gen_loss: 1.2911, disc_loss: 1.2631\n",
      "Time for epoch 592 is 13.5078 sec\n",
      "Epoch 593, gen_loss: 1.3586, disc_loss: 1.2647\n",
      "Time for epoch 593 is 15.1040 sec\n",
      "Epoch 594, gen_loss: 1.8217, disc_loss: 0.8761\n",
      "Time for epoch 594 is 14.2124 sec\n",
      "Epoch 595, gen_loss: 1.4841, disc_loss: 1.1988\n",
      "Time for epoch 595 is 13.4259 sec\n",
      "Epoch 596, gen_loss: 1.6578, disc_loss: 1.0897\n",
      "Time for epoch 596 is 13.7495 sec\n",
      "Epoch 597, gen_loss: 1.8491, disc_loss: 0.9334\n",
      "Time for epoch 597 is 13.3879 sec\n",
      "Epoch 598, gen_loss: 1.4788, disc_loss: 1.1240\n",
      "Time for epoch 598 is 14.2109 sec\n",
      "Epoch 599, gen_loss: 1.3602, disc_loss: 1.2905\n",
      "Time for epoch 599 is 15.0883 sec\n",
      "Epoch 600, gen_loss: 1.5603, disc_loss: 1.1420\n",
      "Time for epoch 600 is 13.4741 sec\n"
     ]
    }
   ],
   "source": [
    "train(dataset, hparas['N_EPOCH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Dataset\n",
    "If you change anything during preprocessing of training dataset, you must make sure same operations have be done in testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_data_generator(caption, index):\n",
    "    caption = tf.cast(caption, tf.float32)\n",
    "    return caption, index\n",
    "\n",
    "def testing_dataset_generator(batch_size, data_generator):\n",
    "    data = pd.read_pickle('./dataset/testData.pkl')\n",
    "    captions = data['Captions'].values\n",
    "    caption = []\n",
    "    for i in range(len(captions)):\n",
    "        caption.append(captions[i])\n",
    "    caption = np.asarray(caption)\n",
    "    caption = caption.astype(np.int64)\n",
    "    index = data['ID'].values\n",
    "    index = np.asarray(index)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((caption, index))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = testing_dataset_generator(hparas['BATCH_SIZE'], testing_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./dataset/testData.pkl')\n",
    "captions = data['Captions'].values\n",
    "\n",
    "NUM_TEST = len(captions)\n",
    "EPOCH_TEST = int(NUM_TEST / hparas['BATCH_SIZE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset):\n",
    "    hidden = text_encoder.initialize_hidden_state()\n",
    "    sample_size = hparas['BATCH_SIZE']\n",
    "    sample_seed = np.random.normal(loc=0.0, scale=1.0, size=(sample_size, hparas['Z_DIM'])).astype(np.float32)\n",
    "    \n",
    "    step = 0\n",
    "    start = time.time()\n",
    "    for captions, idx in dataset:\n",
    "        if step > EPOCH_TEST:\n",
    "            break\n",
    "        \n",
    "        fake_image = test_step(captions, sample_seed, hidden)\n",
    "        step += 1\n",
    "        for i in range(hparas['BATCH_SIZE']):\n",
    "            plt.imsave('./inference/demo/inference_{:04d}.jpg'.format(idx[i]), fake_image[i].numpy()*0.5 + 0.5)\n",
    "            \n",
    "    print('Time for inference is {:.4f} sec'.format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24455fb63d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(checkpoint_dir + '/ckpt-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for inference is 2.7131 sec\n"
     ]
    }
   ],
   "source": [
    "inference(testing_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output score.csv\n",
    "CAUTION: \n",
    "* Please modify GPU setting in <i>inception_score.py</i> if need.\n",
    "* Please run the below cmd in command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'd:\\NTHU\\DL_course\\cup3\\Deep-Learning-Course-Team-Project\\Competition 3\\inception_score.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd testing\n",
    "!python inception_score.py ../inference/demo ../score_demo.csv 39 # BATCH_SIZE=39 is available using GTX 1080 Ti (need 9441MB memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - TA80\n",
    "CAUTION: The code here doesn't work because the inference images aren't provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(idx):\n",
    "    fig = plt.figure(figsize=(14, 14))\n",
    "    \n",
    "    for count, i in enumerate(idx):\n",
    "        loc = np.where(i==index)[0][0]\n",
    "        text = ''\n",
    "        for word in captions[loc]:\n",
    "            if id2word_dict[word] != '<PAD>':\n",
    "                text += id2word_dict[word]\n",
    "                text += ' '\n",
    "        print(text)\n",
    "        \n",
    "        path = './inference/TA80/inference_{:04d}.jpg'.format(i)\n",
    "        fake_iamge = plt.imread(path)\n",
    "        \n",
    "        plt.subplot(7, 7, count+1)\n",
    "        plt.imshow(fake_iamge)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower with white long white petals and very long purple stamen \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './inference/TA80/inference_0023.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22304/673386346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m               7049, 7160]\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mvisualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22304/3780328977.py\u001b[0m in \u001b[0;36mvisualize\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./inference/TA80/inference_{:04d}.jpg'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mfake_iamge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   2137\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2138\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2139\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1558\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1560\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1561\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[0;32m   1562\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2974\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2975\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './inference/TA80/inference_0023.jpg'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1008x1008 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_pickle('./dataset/testData.pkl')\n",
    "captions = data['Captions'].values\n",
    "index = data['ID'].values\n",
    "random_idx = [23, 216, 224, 413, 713, 859, 876, 974, 1177, 1179, 1241, 2169, 2196, 2237, \n",
    "              2356, 2611, 2621, 2786, 2951, 2962, 3145, 3255, 3327, 3639, 3654, 3927, 4262, \n",
    "              4321, 4517, 5067, 5147, 5955, 6167, 6216, 6410, 6413, 6579, 6584, 6804, 6988, \n",
    "              7049, 7160]\n",
    "\n",
    "visualize(random_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './inference/TA80/'\n",
    "img_path = Path(DATA_PATH).glob('*.jpg')\n",
    "img_path = [str(path.resolve()) for path in img_path]\n",
    "img_path = np.asarray(img_path)\n",
    "\n",
    "idx = np.random.randint(len(captions), size=42)\n",
    "idx.sort()\n",
    "\n",
    "random_idx = []\n",
    "for each in idx:\n",
    "    path = img_path[each].split(\"/\")\n",
    "    path = path[-1].replace('inference_', '')\n",
    "    random_idx.append(int(path.replace('.jpg', '')))\n",
    "    \n",
    "visualize(random_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c5b210ffa015f2312f69f2248e3163602cc860559c1494ea467ed1fecf0f25e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
