{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 4 : Unlearnable Dataset\n",
    "`Neural Tangent Generalization Attacks (NTGA)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Download\n",
    "CAUTION: If you nerver download dataset from Kaggle before, plz follow the tutorial in this page: https://www.endtoend.ai/tutorial/how-to-download-kaggle-datasets-on-ubuntu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c datalab-cup4-unlearnable-datasets-cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# zipfile example\n",
    "def zip_list(file_path):\n",
    "    zf = zipfile.ZipFile(file_path, 'r')\n",
    "    if not os.path.exists('dataset'):\n",
    "        os.makedirs('dataset')\n",
    "    zf.extractall('./dataset')\n",
    "\n",
    "file_path = './datalab-cup4-unlearnable-datasets-cifar-10.zip'\n",
    "zip_list(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c datalab-cup4-unlearnable-datasets-imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# zipfile example\n",
    "def zip_list(file_path):\n",
    "    zf = zipfile.ZipFile(file_path, 'r')\n",
    "    if not os.path.exists('dataset'):\n",
    "        os.makedirs('dataset')\n",
    "    zf.extractall('./dataset')\n",
    "\n",
    "file_path = './datalab-cup4-unlearnable-datasets-imagenet.zip'\n",
    "zip_list(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow_addons as tfa\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 16 23:02:11 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\n",
      "| 31%   49C    P8    10W / 250W |     14MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 32%   46C    P0    53W / 250W |      6MiB /  8119MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1266      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1957      G   /usr/bin/gnome-shell                2MiB |\n",
      "|    1   N/A  N/A      1266      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[1], True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'cifar10'\n",
    "# MODE = 'imagenet'\n",
    "\n",
    "if MODE == 'cifar10':\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_CLASSES = 10\n",
    "    IMAGE_HEIGHT = 32\n",
    "    IMAGE_WIDTH = 32\n",
    "if MODE == 'imagenet':\n",
    "    BATCH_SIZE = 128\n",
    "    NUM_CLASSES = 2\n",
    "    IMAGE_HEIGHT = 224\n",
    "    IMAGE_WIDTH = 224\n",
    "    \n",
    "IMAGE_CHANNEL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(f'./dataset/x_train_{MODE}_unlearn.npy')\n",
    "y_train = np.load(f'./dataset/y_train_{MODE}.npy')\n",
    "x_val = np.load(f'./dataset/x_val_{MODE}.npy')\n",
    "y_val = np.load(f'./dataset/y_val_{MODE}.npy')\n",
    "\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(array, noise_factor=0.4):\n",
    "    \"\"\"\n",
    "    Adds random noise to each image in the supplied array.\n",
    "    \"\"\"\n",
    "\n",
    "    noisy_array = array + noise_factor * np.random.normal(\n",
    "        loc=0.0, scale=1.0, size=array.shape\n",
    "    )\n",
    "\n",
    "    return np.clip(noisy_array, 0.0, 1.0)\n",
    "\n",
    "def display(array1, array2):\n",
    "    \"\"\"\n",
    "    Displays ten random images from each one of the supplied arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 10\n",
    "\n",
    "    indices = np.random.randint(len(array1), size=n)\n",
    "    images1 = array1[indices, :]\n",
    "    images2 = array2[indices, :]\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, (image1, image2) in enumerate(zip(images1, images2)):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(image1.reshape(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(image2.reshape(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise to original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import random_noise\n",
    "\n",
    "noise_g = random_noise(x_train, mode='gaussian', clip=True, mean=0, var=0.003) - x_train\n",
    "# noise_sp = random_noise(x_train, mode='s&p', clip=True, salt_vs_pepper=0.5, amount=0.02) - x_train\n",
    "# noise_p = random_noise(x_train, mode='poisson', clip=True) - x_train\n",
    "# noise_s = random_noise(x_train, mode='speckle', clip=True, mean=0, var=0.01) - x_train\n",
    "\n",
    "x_train = x_train + noise_g#+ noise_sp + noise_p + noise_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1608222250>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(len(x_train))\n",
    "plt.imshow(x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_FUNC = None\n",
    "\n",
    "def vertical_flip(tf_img):\n",
    "    return tf.image.flip_left_right(tf_img)\n",
    "\n",
    "def horizontal_flip(tf_img):\n",
    "    return tf.image.flip_up_down(tf_img)\n",
    "\n",
    "def brightness(tf_img):\n",
    "    return tf.image.random_brightness(tf_img, 0.2, 2)\n",
    "\n",
    "def central_crop(tf_img):\n",
    "    img = tf.image.central_crop(tf_img, 0.8)\n",
    "    # img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    return img\n",
    "\n",
    "def noise_injection(tf_img):\n",
    "    noise = tf.random.normal(shape=tf.shape(tf_img), mean=0.0, stddev=1, dtype=tf.float32)\n",
    "    return tf.add(tf_img, noise)\n",
    "\n",
    "def grayscale(tf_img):\n",
    "    img = tf.image.rgb_to_grayscale(tf_img)\n",
    "    return tf.repeat(img, 3, -1)\n",
    "\n",
    "def data_generator(image, label):\n",
    "    # img = tf.cast(image, tf.float32)\n",
    "    # img.set_shape([None, None, IMAGE_CHANNEL])\n",
    "    img = image\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "\n",
    "    if MAPPING_FUNC is not None:\n",
    "        img = MAPPING_FUNC(img)\n",
    "\n",
    "    img = img * 255\n",
    "    img = tf.keras.applications.resnet50.preprocess_input(img) # -1~1\n",
    "    # img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    # img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    label = tf.cast(label, tf.int32)    \n",
    "    return img, label\n",
    "\n",
    "def transform_dataset(image, label):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image, label))\n",
    "    dataset = dataset.map(data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(len(label))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 128, # of batch: 1250\n",
      "Total images: 160000\n"
     ]
    }
   ],
   "source": [
    "MAPPING_FUNC = None\n",
    "original_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "MAPPING_FUNC = grayscale\n",
    "gray_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "MAPPING_FUNC = vertical_flip\n",
    "vertical_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "MAPPING_FUNC = horizontal_flip\n",
    "horizontal_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "MAPPING_FUNC = brightness\n",
    "brightness_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "# MAPPING_FUNC = central_crop\n",
    "# crop_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "# MAPPING_FUNC = noise_injection\n",
    "# noise_dataset = transform_dataset(x_train, y_train)\n",
    "\n",
    "train_dataset = original_dataset\n",
    "# train_dataset = train_dataset.concatenate(gray_dataset)\n",
    "train_dataset = train_dataset.concatenate(vertical_dataset)\n",
    "train_dataset = train_dataset.concatenate(horizontal_dataset)\n",
    "train_dataset = train_dataset.concatenate(brightness_dataset)\n",
    "# train_dataset = train_dataset.concatenate(crop_dataset)\n",
    "# train_dataset = train_dataset.concatenate(noise_dataset)\n",
    "batched_dataset = train_dataset.shuffle(len(y_train)).batch(BATCH_SIZE, drop_remainder=True)\n",
    "batched_dataset = batched_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "print(f'Batch size: {BATCH_SIZE}, # of batch: {len(batched_dataset)}')\n",
    "print(f'Total images: {len(batched_dataset)*BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING_FUNC = None\n",
    "val_dataset = transform_dataset(x_val, y_val)\n",
    "batched_val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 5\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in batched_dataset.take(1):\n",
    "    idx = 36\n",
    "    print(\"Class:\", data[1][idx].numpy())\n",
    "    for i in range(len(data[0])):\n",
    "        assert data[0][i].shape == (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL)\n",
    "    print(data[0][idx].shape)\n",
    "    plt.imshow((data[0][idx]),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_leaky_relu(inputs, filters, size, stride):\n",
    "    x = layers.Conv2D(filters, size, stride, padding=\"same\",\n",
    "                      kernel_initializer=tf.keras.initializers.TruncatedNormal())(inputs)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL)\n",
    "# densenet121 = tf.keras.applications.DenseNet121(\n",
    "#     input_shape=input_shape,\n",
    "#     include_top=False,\n",
    "#     weights=None,\n",
    "#     classes=NUM_CLASSES)\n",
    "# densenet121.trainable = False\n",
    "\n",
    "# inputs = keras.Input(shape=input_shape)\n",
    "# x = densenet121(inputs, training=False)\n",
    "\n",
    "# x = conv_leaky_relu(x, 128, 3, 1)\n",
    "# x = conv_leaky_relu(x, 128, 3, 1)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(128)(x)\n",
    "# x = layers.LeakyReLU(0.1)(x)\n",
    "# x = layers.Dense(128, activation='relu')(x)\n",
    "# outputs = layers.Dense(NUM_CLASSES)(x)\n",
    "\n",
    "# model = keras.Model(inputs=inputs, outputs=outputs, name=\"DenseNet121\")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                                                  'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
      "                                                                  'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
      "                                                                  'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
      "                                                                  'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
      "                                                                  'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
      "                                                                  'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " max_pool (GlobalMaxPooling2D)  (None, 2048)         0           ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           20490       ['max_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,608,202\n",
      "Trainable params: 23,555,082\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=False, \n",
    "    input_tensor=keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL)),\n",
    "    pooling='max',\n",
    "    weights=None)\n",
    "\n",
    "input = resnet.input\n",
    "output = layers.Dense(NUM_CLASSES)(resnet.output)\n",
    "\n",
    "model = keras.Model(input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 23:02:34.863722: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-16 23:02:34.870183: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-16 23:02:34.910136: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-16 23:02:34.920209: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.83GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-16 23:02:34.991299: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-16 23:02:35.001435: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 76s 57ms/step - loss: 2.1288 - acc: 0.2895 - val_loss: 2.0711 - val_acc: 0.2932\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 72s 56ms/step - loss: 1.8743 - acc: 0.3690 - val_loss: 5.0853 - val_acc: 0.2687\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.7238 - acc: 0.4131 - val_loss: 1.5263 - val_acc: 0.4678\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.6022 - acc: 0.4646 - val_loss: 129.6152 - val_acc: 0.2387\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.9301 - acc: 0.3483 - val_loss: 14.0851 - val_acc: 0.2911\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.8802 - acc: 0.3519 - val_loss: 7.6487 - val_acc: 0.3045\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.6856 - acc: 0.4153 - val_loss: 1.7682 - val_acc: 0.4095\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.6625 - acc: 0.4297 - val_loss: 3.3589 - val_acc: 0.4199\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.4809 - acc: 0.4925 - val_loss: 1.7198 - val_acc: 0.5015\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.3981 - acc: 0.5144 - val_loss: 10.0545 - val_acc: 0.2184\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.5070 - acc: 0.4824 - val_loss: 1.4025 - val_acc: 0.5058\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.2119 - acc: 0.5744 - val_loss: 1.3217 - val_acc: 0.5468\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 1.0739 - acc: 0.6224 - val_loss: 1.1931 - val_acc: 0.5990\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.9959 - acc: 0.6524 - val_loss: 1.3685 - val_acc: 0.5533\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.9993 - acc: 0.6544 - val_loss: 1.4405 - val_acc: 0.5865\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.8184 - acc: 0.7147 - val_loss: 1.1374 - val_acc: 0.6296\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.7333 - acc: 0.7449 - val_loss: 1.2266 - val_acc: 0.6288\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.6035 - acc: 0.7898 - val_loss: 1.1941 - val_acc: 0.6452\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.5158 - acc: 0.8206 - val_loss: 1.2498 - val_acc: 0.6509\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.4093 - acc: 0.8586 - val_loss: 1.4859 - val_acc: 0.6231\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.4211 - acc: 0.8565 - val_loss: 1.4698 - val_acc: 0.6315\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.2814 - acc: 0.9022 - val_loss: 1.6889 - val_acc: 0.6176\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.2382 - acc: 0.9182 - val_loss: 1.6642 - val_acc: 0.6271\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1885 - acc: 0.9342 - val_loss: 1.9695 - val_acc: 0.6197\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.2454 - acc: 0.9180 - val_loss: 1.9668 - val_acc: 0.6015\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1312 - acc: 0.9544 - val_loss: 1.9313 - val_acc: 0.6442\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1274 - acc: 0.9555 - val_loss: 2.1791 - val_acc: 0.6090\n",
      "Epoch 28/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1076 - acc: 0.9624 - val_loss: 2.0621 - val_acc: 0.6370\n",
      "Epoch 29/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0995 - acc: 0.9652 - val_loss: 2.3184 - val_acc: 0.6241\n",
      "Epoch 30/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0948 - acc: 0.9665 - val_loss: 2.0676 - val_acc: 0.6424\n",
      "Epoch 31/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0836 - acc: 0.9710 - val_loss: 2.2494 - val_acc: 0.6295\n",
      "Epoch 32/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0806 - acc: 0.9717 - val_loss: 2.2240 - val_acc: 0.6315\n",
      "Epoch 33/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0752 - acc: 0.9738 - val_loss: 2.3264 - val_acc: 0.6412\n",
      "Epoch 34/100\n",
      "1250/1250 [==============================] - 72s 56ms/step - loss: 0.1107 - acc: 0.9638 - val_loss: 2.1290 - val_acc: 0.6487\n",
      "Epoch 35/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0592 - acc: 0.9797 - val_loss: 2.3090 - val_acc: 0.6407\n",
      "Epoch 36/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0600 - acc: 0.9790 - val_loss: 2.2945 - val_acc: 0.6455\n",
      "Epoch 37/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0649 - acc: 0.9773 - val_loss: 2.4904 - val_acc: 0.6328\n",
      "Epoch 38/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0552 - acc: 0.9809 - val_loss: 2.4463 - val_acc: 0.6341\n",
      "Epoch 39/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0543 - acc: 0.9815 - val_loss: 2.3736 - val_acc: 0.6385\n",
      "Epoch 40/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0532 - acc: 0.9820 - val_loss: 2.5120 - val_acc: 0.6343\n",
      "Epoch 41/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1252 - acc: 0.9589 - val_loss: 2.9717 - val_acc: 0.6375\n",
      "Epoch 42/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0338 - acc: 0.9885 - val_loss: 3.0084 - val_acc: 0.6430\n",
      "Epoch 43/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0439 - acc: 0.9847 - val_loss: 2.5525 - val_acc: 0.6368\n",
      "Epoch 44/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1859 - acc: 0.9427 - val_loss: 1.9178 - val_acc: 0.5963\n",
      "Epoch 45/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0631 - acc: 0.9784 - val_loss: 2.4549 - val_acc: 0.6451\n",
      "Epoch 46/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0283 - acc: 0.9905 - val_loss: 2.7634 - val_acc: 0.6299\n",
      "Epoch 47/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0908 - acc: 0.9719 - val_loss: 1.8338 - val_acc: 0.6335\n",
      "Epoch 48/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0571 - acc: 0.9805 - val_loss: 2.5394 - val_acc: 0.6444\n",
      "Epoch 49/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0297 - acc: 0.9898 - val_loss: 2.7556 - val_acc: 0.6384\n",
      "Epoch 50/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0384 - acc: 0.9867 - val_loss: 2.5483 - val_acc: 0.6471\n",
      "Epoch 51/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0402 - acc: 0.9858 - val_loss: 2.4982 - val_acc: 0.6450\n",
      "Epoch 52/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0376 - acc: 0.9871 - val_loss: 2.6083 - val_acc: 0.6456\n",
      "Epoch 53/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0379 - acc: 0.9869 - val_loss: 2.7760 - val_acc: 0.6370\n",
      "Epoch 54/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0374 - acc: 0.9873 - val_loss: 2.4885 - val_acc: 0.6553\n",
      "Epoch 55/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0423 - acc: 0.9853 - val_loss: 2.4074 - val_acc: 0.6472\n",
      "Epoch 56/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0314 - acc: 0.9891 - val_loss: 2.6101 - val_acc: 0.6428\n",
      "Epoch 57/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0335 - acc: 0.9885 - val_loss: 2.8737 - val_acc: 0.6261\n",
      "Epoch 58/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0330 - acc: 0.9887 - val_loss: 2.6619 - val_acc: 0.6439\n",
      "Epoch 59/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0308 - acc: 0.9895 - val_loss: 2.5953 - val_acc: 0.6457\n",
      "Epoch 60/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0313 - acc: 0.9892 - val_loss: 2.5149 - val_acc: 0.6491\n",
      "Epoch 61/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0313 - acc: 0.9894 - val_loss: 2.6079 - val_acc: 0.6426\n",
      "Epoch 62/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0295 - acc: 0.9897 - val_loss: 2.7975 - val_acc: 0.6349\n",
      "Epoch 63/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0297 - acc: 0.9901 - val_loss: 2.7286 - val_acc: 0.6431\n",
      "Epoch 64/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0281 - acc: 0.9907 - val_loss: 2.7954 - val_acc: 0.6374\n",
      "Epoch 65/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0272 - acc: 0.9908 - val_loss: 2.5969 - val_acc: 0.6530\n",
      "Epoch 66/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0263 - acc: 0.9907 - val_loss: 2.6552 - val_acc: 0.6524\n",
      "Epoch 67/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0274 - acc: 0.9907 - val_loss: 2.6346 - val_acc: 0.6602\n",
      "Epoch 68/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0516 - acc: 0.9847 - val_loss: 2.7239 - val_acc: 0.6578\n",
      "Epoch 69/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0162 - acc: 0.9946 - val_loss: 3.0995 - val_acc: 0.6317\n",
      "Epoch 70/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0225 - acc: 0.9924 - val_loss: 2.8355 - val_acc: 0.6433\n",
      "Epoch 71/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0241 - acc: 0.9920 - val_loss: 2.6657 - val_acc: 0.6526\n",
      "Epoch 72/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0254 - acc: 0.9913 - val_loss: 2.9727 - val_acc: 0.6317\n",
      "Epoch 73/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0239 - acc: 0.9919 - val_loss: 2.7226 - val_acc: 0.6542\n",
      "Epoch 74/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0238 - acc: 0.9920 - val_loss: 2.8045 - val_acc: 0.6447\n",
      "Epoch 75/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0252 - acc: 0.9918 - val_loss: 2.9646 - val_acc: 0.6345\n",
      "Epoch 76/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0238 - acc: 0.9919 - val_loss: 2.6605 - val_acc: 0.6536\n",
      "Epoch 77/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0227 - acc: 0.9924 - val_loss: 2.7688 - val_acc: 0.6345\n",
      "Epoch 78/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0223 - acc: 0.9929 - val_loss: 3.3106 - val_acc: 0.6058\n",
      "Epoch 79/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.1153 - acc: 0.9657 - val_loss: 2.9771 - val_acc: 0.6519\n",
      "Epoch 80/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 3.0070 - val_acc: 0.6555\n",
      "Epoch 81/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0116 - acc: 0.9961 - val_loss: 3.1999 - val_acc: 0.6456\n",
      "Epoch 82/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 3.0539 - val_acc: 0.6409\n",
      "Epoch 83/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0264 - acc: 0.9910 - val_loss: 2.7544 - val_acc: 0.6627\n",
      "Epoch 84/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0178 - acc: 0.9941 - val_loss: 2.8617 - val_acc: 0.6519\n",
      "Epoch 85/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0253 - acc: 0.9916 - val_loss: 2.7898 - val_acc: 0.6576\n",
      "Epoch 86/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0180 - acc: 0.9940 - val_loss: 3.0327 - val_acc: 0.6451\n",
      "Epoch 87/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0201 - acc: 0.9932 - val_loss: 2.8844 - val_acc: 0.6508\n",
      "Epoch 88/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0190 - acc: 0.9938 - val_loss: 2.8383 - val_acc: 0.6486\n",
      "Epoch 89/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0204 - acc: 0.9931 - val_loss: 2.8910 - val_acc: 0.6435\n",
      "Epoch 90/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0233 - acc: 0.9924 - val_loss: 2.8028 - val_acc: 0.6546\n",
      "Epoch 91/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0213 - acc: 0.9932 - val_loss: 2.8794 - val_acc: 0.6485\n",
      "Epoch 92/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0181 - acc: 0.9939 - val_loss: 2.8704 - val_acc: 0.6559\n",
      "Epoch 93/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0171 - acc: 0.9945 - val_loss: 3.1243 - val_acc: 0.6398\n",
      "Epoch 94/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0220 - acc: 0.9930 - val_loss: 2.8445 - val_acc: 0.6496\n",
      "Epoch 95/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0173 - acc: 0.9942 - val_loss: 2.9114 - val_acc: 0.6451\n",
      "Epoch 96/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0186 - acc: 0.9938 - val_loss: 2.8512 - val_acc: 0.6478\n",
      "Epoch 97/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0162 - acc: 0.9946 - val_loss: 2.8335 - val_acc: 0.6592\n",
      "Epoch 98/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0190 - acc: 0.9936 - val_loss: 2.8976 - val_acc: 0.6629\n",
      "Epoch 99/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0167 - acc: 0.9943 - val_loss: 3.0464 - val_acc: 0.6449\n",
      "Epoch 100/100\n",
      "1250/1250 [==============================] - 72s 57ms/step - loss: 0.0163 - acc: 0.9945 - val_loss: 2.7746 - val_acc: 0.6567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=batched_dataset, validation_data=batched_val_dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606914059817791"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load(f'./dataset/x_test_{MODE}.npy')\n",
    "print(x_test.shape)\n",
    "x_test = autoencoder.predict(x_test)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generator(image):\n",
    "    # img = tf.cast(image, tf.float32)\n",
    "    # img.set_shape([None, None, IMAGE_CHANNEL])\n",
    "    \n",
    "    img = image\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    img = tf.image.grayscale_to_rgb(img)\n",
    "\n",
    "    img = img * 255\n",
    "    img = tf.keras.applications.resnet50.preprocess_input(img)\n",
    "\n",
    "    # img = tf.image.resize(img, size=[IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    # img.set_shape([IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNEL])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000 79\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load(f'./dataset/x_test_{MODE}.npy')\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test))\n",
    "test_dataset = test_dataset.map(test_data_generator, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "batched_test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "print(len(x_test), len(test_dataset), len(batched_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-17 01:04:20.789549: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-01-17 01:04:20.793795: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x=batched_test_dataset)\n",
    "final_result = np.argmax(result, axis=1)\n",
    "output = pd.DataFrame({'id':range(len(final_result)), 'label':final_result})\n",
    "output.to_csv(f'./submission_{MODE}.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c5b210ffa015f2312f69f2248e3163602cc860559c1494ea467ed1fecf0f25e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
