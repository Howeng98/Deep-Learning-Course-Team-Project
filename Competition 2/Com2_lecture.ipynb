{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLab Cup 2: CNN for Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_name =  [\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \n",
    "                 \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "                 \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \n",
    "                 \"sheep\", \"sofa\", \"train\",\"tvmonitor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000005.jpg 263 211 324 339 8 165 264 253 372 8 5 244 67 374 8 241 194 295 299 8 277 186 312 220 8\n",
      "000007.jpg 141 50 500 330 6\n",
      "000009.jpg 69 172 270 330 12 150 141 229 284 14 285 201 327 331 14 258 198 297 329 14\n",
      "000012.jpg 156 97 351 270 6\n",
      "000016.jpg 92 72 305 473 1\n",
      "000017.jpg 185 62 279 199 14 90 78 403 336 12\n"
     ]
    }
   ],
   "source": [
    "training_data_file = open(\"./dataset/pascal_voc_training_data.txt\", \"r\")\n",
    "for i, line in enumerate(training_data_file):\n",
    "    if i >5:\n",
    "        break\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params\n",
    "IMAGE_SIZE = 448\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 20\n",
    "MAX_OBJECTS_PER_IMAGE = 20\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = './dataset/pascal_voc_training_data.txt'\n",
    "IMAGE_DIR = './dataset/VOCdevkit_train/VOC2007/JPEGImages/'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    Load pascalVOC 2007 dataset and creates an input pipeline.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(ss[0])\n",
    "\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, \n",
    "                                            MAX_OBJECTS_PER_IMAGE))\n",
    "            if len(self.record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                # if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [0., 0., 0., 0., 0.]*\\\n",
    "                (MAX_OBJECTS_PER_IMAGE-len(self.record_list[-1])//5)\n",
    "                \n",
    "            elif len(self.record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "               # if there are objects more than MAX_OBJECTS_PER_IMAGE, crop the list\n",
    "                self.record_list[-1] = self.record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(IMAGE_DIR+image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_ratio  = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_ratio = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "        image = (image/255) * 2 - 1\n",
    "\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xmin = raw_labels[:, 0]\n",
    "        ymin = raw_labels[:, 1]\n",
    "        xmax = raw_labels[:, 2]\n",
    "        ymax = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        xcenter = (xmin + xmax) * 1.0 / 2.0 * width_ratio\n",
    "        ycenter = (ymin + ymax) * 1.0 / 2.0 * height_ratio\n",
    "\n",
    "        box_w = (xmax - xmin) * width_ratio\n",
    "        box_h = (ymax - ymin) * height_ratio\n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis=1)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "\n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                      np.array(self.record_list), \n",
    "                                                      np.array(self.object_num_list)))\n",
    "        dataset = dataset.shuffle(100000)\n",
    "        dataset = dataset.map(self._data_preprocess, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        dataset = dataset.prefetch(buffer_size=200)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Model (YOLO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_leaky_relu(inputs, filters, size, stride):\n",
    "    x = layers.Conv2D(filters, size, stride, padding=\"same\",\n",
    "                      kernel_initializer=tf.keras.initializers.TruncatedNormal())(inputs)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = conv_leaky_relu(img_inputs, 64, 7, 2)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 192, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 128, 1, 1)\n",
    "x = conv_leaky_relu(x, 256, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 2)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, \n",
    "                 kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = layers.LeakyReLU(0.1)(x)\n",
    "outputs = layers.Dense(1470, \n",
    "                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLO\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 448, 448, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      9472      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 224, 224, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 192)     110784    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 112, 112, 192)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 192)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 128)       24704     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 56, 56, 256)       65792     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 56, 56, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 56, 56, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 28, 28, 512)       262656    \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 28, 28, 512)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 28, 28, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 28, 28, 1024)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 1024)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 14, 14, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 1024)      9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 14, 14, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 7, 7, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              205524992 \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1470)              6022590   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,703,550\n",
      "Trainable params: 271,703,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "# initializtion for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, \n",
    "                               IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4])\n",
    "base_boxes = np.tile(base_boxes, [1, 1, BOXES_PER_CELL, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "\n",
    "    Return:\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "      ====> iou score for each cell\n",
    "    \"\"\"\n",
    "\n",
    "    #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "\n",
    "    #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu \n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "def losses_calculation(predict, label):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict: 3-D tensor [cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "      label : [1, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #Step A. calculate objects tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #turn pixel position into cell position (corner)\n",
    "    min_x = (label[0] - label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_x = (label[0] + label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_y = (label[1] + label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "\n",
    "    max_x = tf.minimum(tf.math.ceil(max_x), CELL_SIZE)\n",
    "    max_y = tf.minimum(tf.math.ceil(max_y), CELL_SIZE)\n",
    "    \n",
    "    #calculate mask of object with cells\n",
    "    onset = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    object_mask = tf.ones(onset, tf.float32)\n",
    "\n",
    "    offset = tf.cast(tf.stack([min_y, CELL_SIZE - max_y, min_x, CELL_SIZE - max_x]), tf.int32)\n",
    "    offset = tf.reshape(offset, (2, 2))\n",
    "    object_mask = tf.pad(object_mask, offset, \"CONSTANT\")\n",
    "\n",
    "    #Step B. calculate the coordination of object center and the corresponding mask\n",
    "    #turn pixel position into cell position (center)\n",
    "    center_x = label[0] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    #calculate the coordination of object center with cells\n",
    "    objects_center_coord = tf.cast(tf.stack([center_y, CELL_SIZE - center_y - 1, \n",
    "                             center_x, CELL_SIZE - center_x - 1]), \n",
    "                             tf.int32)\n",
    "    objects_center_coord = tf.reshape(objects_center_coord, (2, 2))\n",
    "\n",
    "    #make mask\n",
    "    response = tf.pad(response, objects_center_coord, \"CONSTANT\")\n",
    "\n",
    "    #Step C. calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    predict_boxes = predict[:, :, NUM_CLASSES + BOXES_PER_CELL:]\n",
    "\n",
    "    predict_boxes = tf.reshape(predict_boxes, [CELL_SIZE, \n",
    "                                               CELL_SIZE, \n",
    "                                               BOXES_PER_CELL, 4])\n",
    "    #cell position to pixel position\n",
    "    predict_boxes = predict_boxes * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "\n",
    "    #calculate C tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    C = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    I = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    #replace large iou scores with response (object center) value\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I\n",
    "\n",
    "    p_C = predict[:, :, NUM_CLASSES:NUM_CLASSES + BOXES_PER_CELL]\n",
    "\n",
    "    #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "\n",
    "    #calculate ground truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "    #calculate predicted p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:NUM_CLASSES]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(object_mask, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * OBJECT_SCALE\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * NOOBJECT_SCALE\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_y - y)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/IMAGE_SIZE +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/IMAGE_SIZE) * COORD_SCALE\n",
    "\n",
    "    return class_loss + object_loss + noobject_loss + coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(predicts, labels, objects_num):\n",
    "    \"\"\"\n",
    "    Add Loss to all the trainable variables\n",
    "    Args:\n",
    "        predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "        labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "        objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.\n",
    "    \n",
    "    #you can parallel the code with tf.map_fn or tf.vectorized_map (big performance gain!)\n",
    "    for i in tf.range(BATCH_SIZE):\n",
    "        predict = predicts[i, :, :, :]\n",
    "        label = labels[i, :, :]\n",
    "        object_num = objects_num[i]\n",
    "\n",
    "        for j in tf.range(object_num):\n",
    "            results = losses_calculation(predict, label[j:j+1, :])\n",
    "            loss = loss + results\n",
    "\n",
    "    return loss/BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetGenerator().generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(epoch=tf.Variable(0), net=YOLO)\n",
    "\n",
    "manager = tf.train.CheckpointManager(ckpt, './ckpts/YOLO', max_to_keep=3,\n",
    "                                     checkpoint_name='yolo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = YOLO(image)\n",
    "        class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "        conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "        class_probs = tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "        confs = tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "        boxes = tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "\n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "        train_loss_metric(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-15 01:12:27.114167, start training.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa8 in position 101: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5628/281993523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mckpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjects_num\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjects_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    798\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 783\u001b[1;33m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[0;32m    784\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   2837\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2838\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2839\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   2840\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"IteratorGetNext\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2841\u001b[0m         \"output_shapes\", output_shapes)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa8 in position 101: invalid start byte"
     ]
    }
   ],
   "source": [
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "for i in range(EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "    ckpt.epoch.assign_add(1)\n",
    "\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "        train_step(image, labels, objects_num)\n",
    "\n",
    "    print(\"{}, Epoch {}: loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bou\n",
    "    \"\"\"\n",
    "\n",
    "    class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 20))\n",
    "    confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:20]\n",
    "    C = predicts[0, :, :, 20:22]\n",
    "    coordinate = predicts[0, :, :, 22:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 20))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P = C * p_classes\n",
    "    #P's shape [7, 7, 2, 20]\n",
    "\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "    ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "    w = w * IMAGE_SIZE\n",
    "    h = h * IMAGE_SIZE\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('./dataset/pascal_voc_testing_data.txt')\n",
    "test_img_dir = './dataset/VOCdevkit_test/VOC2007/JPEGImages/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(ss[0])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(test_img_dir+image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = (image/255) * 2 - 1\n",
    "\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(net=YOLO)\n",
    "ckpt.restore('./ckpts/YOLO/yolo-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make prediction and output to txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open('./output/test_prediction.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    batch_num = img_name.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_outputs(prediction_step(test_img[i:i+1]))\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w[i:i+1]/IMAGE_SIZE), ymin*(img_h[i:i+1]/IMAGE_SIZE), xmax*(img_w[i:i+1]/IMAGE_SIZE), ymax*(img_h[i:i+1]/IMAGE_SIZE)\n",
    "\n",
    "        #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "        output_file.write(img_name[i:i+1].numpy()[0].decode('ascii')+\" %d %d %d %d %d %f\\n\" %(xmin, ymin, xmax, ymax, class_num, conf))\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/test_prediction.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5628/816948401.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./output/test_prediction.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./output/output_file.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Che\\Desktop\\清大\\深度學習\\Deep-Learning-Course-Team-Project\\Competition 2\\./dataset/evaluate\\evaluate.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(predict_file, output_csv_file)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m     \u001b[0mpred_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m     \u001b[1;31m#pred_boundingBoxes = BoundingBoxes()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtest_case\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/test_prediction.txt'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "#evaluate.evaluate(\"input prediction file name\", \"desire output csv file name\")\n",
    "evaluate.evaluate('./output/test_prediction.txt', './output/output_file.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_img = cv2.imread('./dataset/VOCdevkit_test/VOC2007/JPEGImages/000002.jpg')\n",
    "resized_img = cv2.resize(np_img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "np_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "resized_img = np_img\n",
    "np_img = np_img.astype(np.float32)\n",
    "np_img = np_img / 255.0 * 2 - 1\n",
    "np_img = np.reshape(np_img, (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "y_pred = YOLO(np_img, training=False)\n",
    "xmin, ymin, xmax, ymax, class_num, conf = process_outputs(y_pred)\n",
    "class_name = classes_name[class_num]\n",
    "cv2.rectangle(resized_img, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 255), 3)\n",
    "cv2.putText(resized_img, class_name, (0, 200), 2, 1.5, (0, 255, 255), 2)\n",
    "\n",
    "plt.imshow(resized_img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "22c6df8416d99150f2220dbf1611e4fb62265fefa3bde7b85f317bcaabf8ed29"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
